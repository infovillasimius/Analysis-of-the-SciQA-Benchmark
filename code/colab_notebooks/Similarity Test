{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNE4xo+eLGjwYri/Sahfs8p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd drive/MyDrive/en2sparql"],"metadata":{"id":"YcU-KRrrF9JR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692294381604,"user_tz":-120,"elapsed":24680,"user":{"displayName":"Antonello","userId":"01962207529893687178"}},"outputId":"ccb7d6b5-2e38-4c6b-f98e-ff707daef764"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/en2sparql\n"]}]},{"cell_type":"code","source":["!pip install rouge\n","import nltk\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gk0ZzrPa4LFQ","executionInfo":{"status":"ok","timestamp":1692294397158,"user_tz":-120,"elapsed":9304,"user":{"displayName":"Antonello","userId":"01962207529893687178"}},"outputId":"ea897481-8e74-4c8c-b89f-8a1ea9b7e499"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import re\n","from collections import Counter\n","from typing import List\n","\n","from nltk.translate.meteor_score import single_meteor_score\n","from nltk.translate.bleu_score import sentence_bleu\n","from rouge import Rouge\n","import csv\n","import json\n","\n","def rogue_score(rog_score):\n","    rouge_1_sum = 0\n","    rouge_2_sum = 0\n","    rouge_l_sum = 0\n","    num_scores = len(rog_score)\n","    for score in rog_score:\n","        rouge_1_sum += score['rouge-1']['f']\n","        rouge_2_sum += score['rouge-2']['f']\n","        rouge_l_sum += score['rouge-l']['f']\n","    rouge_1_avg = rouge_1_sum / num_scores\n","    rouge_2_avg = rouge_2_sum / num_scores\n","    rouge_l_avg = rouge_l_sum / num_scores\n","    return rouge_1_avg,rouge_2_avg, rouge_l_avg\n","\n","def mask(txt: str) -> str:\n","    \"\"\"\n","    Replace any sequence starting with \"?\" followed by any word character with \"?MASKED\"\n","\n","    Args:\n","        txt (str): input text\n","\n","    Returns:\n","        str: the masked text\n","    \"\"\"\n","    masked = re.sub(r'\\?\\w+', '?MASKED', txt)\n","    return masked\n","\n","def metric_em(path_to_predictions: str, language: str) -> int:\n","    \"\"\"\n","    Calculate the exact match (EM) metric for the model.\n","\n","    Args:\n","        path_to_predictions (str): the path to the CSV file containing the predictions\n","        language (str): the language of the predictions\n","\n","    Returns:\n","        int: the number of hits (correct predictions)\n","    \"\"\"\n","    hits: List[str] = []\n","    indices: List[int] = []\n","    with open(path_to_predictions, 'r') as file:\n","        csvreader = csv.reader(file)\n","        header = next(csvreader)\n","        gt, mt = [], []\n","        for row in csvreader:\n","            gt.append(row[1].strip())\n","            mt.append(row[2].strip())\n","\n","    counter = 0\n","    for i, (gt_row, mt_row) in enumerate(zip(gt, mt)):\n","        if language == \"sparql\":\n","            gt_row = mask(gt_row)\n","            mt_row = mask(mt_row)\n","        gt_res = \" \".join(gt_row.split()).strip()\n","        mt_res = \" \".join(mt_row.split()).strip()\n","        if gt_res == mt_res:\n","            hits.append(gt_res)\n","            indices.append(i)\n","            counter += 1\n","\n","    return len(hits)\n","\n","def format_text(txt):\n","    \"\"\"\n","    This function formats the input text by:\n","    1. Converting the text to lowercase\n","    2. Removing punctuations\n","    3. Removing articles (a, an, the)\n","    4. Fixing white spaces\n","    \"\"\"\n","    RE_ART = re.compile(r'\\b(a|an|the)\\b')\n","    RE_PUNC = re.compile(r'[!\"#$%&()*+,-./:;<=>?@\\[\\]\\\\^`{|}~_\\']')\n","    lower = txt.lower()\n","    remove_punc = RE_PUNC.sub(' ', lower)\n","    remove_articles = RE_ART.sub(' ', remove_punc)\n","    fix_white_space = ' '.join(remove_articles.split())\n","    return fix_white_space\n","\n","def evaluate(predicted_output, actual_output, metrics=['precision', 'recall', 'bleu', 'rogue']):\n","    \"\"\"\n","    This function evaluates the given predicted_output against the actual_output using multiple metrics.\n","    Returns the following metrics: precision, recall, F1 score, BLEU (cumulative), METEOR, Rouge, BLEU-4.\n","    \"\"\"\n","    rouge = Rouge()\n","    common = Counter(predicted_output.split()) & Counter(actual_output.split())\n","    num_same = sum(common.values())\n","    precision_score = 1.0 * num_same / len(predicted_output.split())\n","    recall_score = 1.0 * num_same / len(actual_output.split())\n","\n","    if precision_score == 0 or recall_score == 0:\n","        f1_score = 0\n","    else:\n","        f1_score = (2 * precision_score * recall_score) / (precision_score + recall_score)\n","\n","    meteor = single_meteor_score([actual_output], [predicted_output])\n","    ro = rouge.get_scores(actual_output, predicted_output, avg=True)\n","    bleu_c = sentence_bleu([actual_output.split()], predicted_output.split(), weights=(0.25, 0.25, 0.25, 0.25))\n","    bleu_4 = sentence_bleu([actual_output.split()], predicted_output.split(), weights=(0, 0, 0, 1))\n","\n","    return precision_score, recall_score, f1_score, bleu_c, meteor, ro, bleu_4\n","\n","def run_eval(predictions, quer):\n","    predictions = [format_text(i) for i in predictions]\n","    quer = [format_text(i) for i in quer]\n","\n","    precision, recall, f1_score, bleu_score_c, meteor_score, rog_score, bleu_score_4 = [], [], [], [], [], [], []\n","\n","    for i, j in zip(predictions, quer):\n","        prec, rec, f1, bleuc, met, rog, bleu4 = evaluate(i, j)\n","        precision.append(prec)\n","        recall.append(rec)\n","        f1_score.append(f1)\n","        bleu_score_c.append(bleuc)\n","        meteor_score.append(met)\n","        rog_score.append(rog)\n","        bleu_score_4.append(bleu4)\n","\n","    print(f'Precision: {sum(precision)/len(precision)}, Recall : {sum(recall)/len(recall)}, F1 Score: {sum(f1_score)/len(f1_score)}, Blue 4: {sum(bleu_score_4)/len(bleu_score_4)}, Bleu Score Cumulative: {sum(bleu_score_c)/len(bleu_score_c)}, Meteor Score: {sum(meteor_score)/len(meteor_score)}')\n","\n","    rouge_1_avg, rouge_2_avg, rouge_l_avg = rogue_score(rog_score)\n","    print(f'Rouge-1: {rouge_1_avg}, Rouge-2: {rouge_2_avg}, Rouge-L: {rouge_l_avg}')\n","    return {\"Precision\": sum(precision)/len(precision),\n","            \"Recall\": sum(recall)/len(recall),\n","            \"F1_Score\": sum(f1_score)/len(f1_score),\n","            \"Blue_4\": sum(bleu_score_4)/len(bleu_score_4),\n","            \"Bleu_Score_Cumulative\": sum(bleu_score_c) / len(bleu_score_c),\n","            \"Meteor_Score\": sum(meteor_score) / len(meteor_score),\n","            \"Rouge_1\": rouge_1_avg,\n","            \"Rouge_2\": rouge_2_avg,\n","            \"Rouge_L\": rouge_l_avg\n","            }\n","\n","\n"],"metadata":{"id":"28tFQ5BV37yH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import csv\n","import json\n","import os.path\n","\n","\n","def load_json(file__name):\n","    data_file = open(file__name, \"r\", encoding='utf-8')\n","    file_data = json.loads(data_file.read())\n","    data_file.close()\n","    return file_data\n","\n","\n","def write_json(file__name, content):\n","    with open(file__name, \"w\", encoding=\"utf-8\") as text_file:\n","        print(json.dumps(content), file=text_file)\n","\n","\n","def run_tests(shots=1,threshold=0.1):\n","  results = {}\n","  prefix = \"json/\"\n","  filename = prefix + \"nlp_dolly_\" + str(shots) + \"_shot_results_cleaned.json\"\n","  if not os.path.isfile(filename):\n","    return {}\n","  data = load_json(filename)\n","  # print(len(data[\"suggestions\"]))\n","  results[\"shots\"] = shots\n","  results[\"Generated\"] = len(data[\"suggestions\"])\n","  results[\"threshold\"] = threshold\n","  sim_mean = 0\n","  generated =[]\n","  sparql = []\n","  for i, sample in enumerate(data[\"suggestions\"]):\n","    elem_sim = 0\n","    r_list = sample[0]\n","    r = sample[1]\n","    for r_elem in r_list:\n","      if r_elem[1] == r:\n","        sim_mean += 1 / len(r_list)\n","        elem_sim += 1 / len(r_list)\n","        # print(r_elem[1], r)\n","    if elem_sim >= threshold:\n","      generated.append(data[\"cleaned_sparql\"][i])\n","      sparql.append(data[\"sparql\"][i])\n","  results[\"samples_above_theshold\"] = len(generated)\n","  results[\"sim_mean_n\"] = sim_mean\n","  results[\"sim_mean_%\"] =  sim_mean/len(data[\"suggestions\"])*100\n","\n","  metrics = run_eval(generated,sparql)\n","  for key in metrics:\n","    results[key] = metrics.get(key)\n","  return results\n","\n","def write_csv(filename_,content):\n","    with open(filename_, 'w', newline='', encoding=\"utf-8\") as file:\n","        writer = csv.writer(file, delimiter='\\t')\n","        writer.writerows(content)\n","\n","\n","def main():\n","  res = []\n","  for i in range(8):\n","    if i == 0:\n","      continue\n","    res.append(run_tests(shots=i))\n","  print(json.dumps(res))\n","  table = {}\n","  for row in res:\n","    for key in row:\n","      if key in table:\n","        table[key].append(row.get(key))\n","      else:\n","        table[key]=[row.get(key)]\n","  print(table)\n","  rows = []\n","  for key in table:\n","    rows.append([key] + table.get(key))\n","  write_csv(\"nl_similarity_results.csv\",rows)\n","\n","\n","main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XkE7sB5rvlJ","executionInfo":{"status":"ok","timestamp":1692297732261,"user_tz":-120,"elapsed":11961,"user":{"displayName":"Antonello","userId":"01962207529893687178"}},"outputId":"0d41ecfb-3d1b-460f-ea70-0ff68462df9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Precision: 0.9302987679880345, Recall : 0.9582156787537927, F1 Score: 0.9356401444088542, Blue 4: 0.8608706871043914, Bleu Score Cumulative: 0.8833711816037341, Meteor Score: 0.2191142191142191\n","Rouge-1: 0.9281387129874333, Rouge-2: 0.9176012584172245, Rouge-L: 0.926894660927173\n","Precision: 0.8490551879768369, Recall : 0.9614639739231818, F1 Score: 0.883846037980734, Blue 4: 0.802022056789912, Bleu Score Cumulative: 0.8188051699183908, Meteor Score: 0.2365038560411311\n","Rouge-1: 0.9047341889793871, Rouge-2: 0.8983643222696338, Rouge-L: 0.903324957939787\n","Precision: 0.8391496081148198, Recall : 0.9700920192087632, F1 Score: 0.8791537672184582, Blue 4: 0.8062324613577251, Bleu Score Cumulative: 0.8190625694705936, Meteor Score: 0.24447513812154695\n","Rouge-1: 0.9221275742997038, Rouge-2: 0.919369592409375, Rouge-L: 0.9216488896063387\n","Precision: 0.8239332973645072, Recall : 0.974732250009244, F1 Score: 0.8685071800659993, Blue 4: 0.7920450166105034, Bleu Score Cumulative: 0.8041497607497559, Meteor Score: 0.2551928783382789\n","Rouge-1: 0.9162429508855462, Rouge-2: 0.9123366294427875, Rouge-L: 0.9149648048361684\n","Precision: 0.8235277332086985, Recall : 0.9800131243237701, F1 Score: 0.8696876641735878, Blue 4: 0.7920379980732509, Bleu Score Cumulative: 0.8042812385090181, Meteor Score: 0.2390625\n","Rouge-1: 0.9091443486958266, Rouge-2: 0.9114370061808973, Rouge-L: 0.9072523881498528\n","Precision: 0.8356702526443539, Recall : 0.9909147217288845, F1 Score: 0.8825329052431538, Blue 4: 0.8116430951493884, Bleu Score Cumulative: 0.821204171304195, Meteor Score: 0.27346278317152106\n","Rouge-1: 0.91537808750923, Rouge-2: 0.9186155296872831, Rouge-L: 0.9149194573919717\n","Precision: 0.8080501150431385, Recall : 0.9724697275497102, F1 Score: 0.8543444890988692, Blue 4: 0.7746400999589358, Bleu Score Cumulative: 0.7846482772684893, Meteor Score: 0.24155405405405406\n","Rouge-1: 0.895922365080103, Rouge-2: 0.8997813029758835, Rouge-L: 0.8952646414356874\n","[{\"shots\": 1, \"Generated\": 513, \"threshold\": 0.95, \"samples_above_theshold\": 429, \"sim_mean_n\": 429.0, \"sim_mean_%\": 83.62573099415205, \"Precision\": 0.9302987679880345, \"Recall\": 0.9582156787537927, \"F1_Score\": 0.9356401444088542, \"Blue_4\": 0.8608706871043914, \"Bleu_Score_Cumulative\": 0.8833711816037341, \"Meteor_Score\": 0.2191142191142191, \"Rouge_1\": 0.9281387129874333, \"Rouge_2\": 0.9176012584172245, \"Rouge_L\": 0.926894660927173}, {\"shots\": 2, \"Generated\": 513, \"threshold\": 0.95, \"samples_above_theshold\": 389, \"sim_mean_n\": 430.0, \"sim_mean_%\": 83.82066276803118, \"Precision\": 0.8490551879768369, \"Recall\": 0.9614639739231818, \"F1_Score\": 0.883846037980734, \"Blue_4\": 0.802022056789912, \"Bleu_Score_Cumulative\": 0.8188051699183908, \"Meteor_Score\": 0.2365038560411311, \"Rouge_1\": 0.9047341889793871, \"Rouge_2\": 0.8983643222696338, \"Rouge_L\": 0.903324957939787}, {\"shots\": 3, \"Generated\": 513, \"threshold\": 0.95, \"samples_above_theshold\": 362, \"sim_mean_n\": 429.6666666666597, \"sim_mean_%\": 83.75568551007011, \"Precision\": 0.8391496081148198, \"Recall\": 0.9700920192087632, \"F1_Score\": 0.8791537672184582, \"Blue_4\": 0.8062324613577251, \"Bleu_Score_Cumulative\": 0.8190625694705936, \"Meteor_Score\": 0.24447513812154695, \"Rouge_1\": 0.9221275742997038, \"Rouge_2\": 0.919369592409375, \"Rouge_L\": 0.9216488896063387}, {\"shots\": 4, \"Generated\": 513, \"threshold\": 0.95, \"samples_above_theshold\": 337, \"sim_mean_n\": 428.5, \"sim_mean_%\": 83.52826510721248, \"Precision\": 0.8239332973645072, \"Recall\": 0.974732250009244, \"F1_Score\": 0.8685071800659993, \"Blue_4\": 0.7920450166105034, \"Bleu_Score_Cumulative\": 0.8041497607497559, \"Meteor_Score\": 0.2551928783382789, \"Rouge_1\": 0.9162429508855462, \"Rouge_2\": 0.9123366294427875, \"Rouge_L\": 0.9149648048361684}, {\"shots\": 5, \"Generated\": 513, \"threshold\": 0.95, \"samples_above_theshold\": 320, \"sim_mean_n\": 429.79999999998415, \"sim_mean_%\": 83.78167641325227, \"Precision\": 0.8235277332086985, \"Recall\": 0.9800131243237701, \"F1_Score\": 0.8696876641735878, \"Blue_4\": 0.7920379980732509, \"Bleu_Score_Cumulative\": 0.8042812385090181, \"Meteor_Score\": 0.2390625, \"Rouge_1\": 0.9091443486958266, \"Rouge_2\": 0.9114370061808973, \"Rouge_L\": 0.9072523881498528}, {\"shots\": 6, \"Generated\": 513, \"threshold\": 0.95, \"samples_above_theshold\": 309, \"sim_mean_n\": 431.83333333334747, \"sim_mean_%\": 84.17803768681237, \"Precision\": 0.8356702526443539, \"Recall\": 0.9909147217288845, \"F1_Score\": 0.8825329052431538, \"Blue_4\": 0.8116430951493884, \"Bleu_Score_Cumulative\": 0.821204171304195, \"Meteor_Score\": 0.27346278317152106, \"Rouge_1\": 0.91537808750923, \"Rouge_2\": 0.9186155296872831, \"Rouge_L\": 0.9149194573919717}, {\"shots\": 7, \"Generated\": 513, \"threshold\": 0.95, \"samples_above_theshold\": 296, \"sim_mean_n\": 433.14285714288246, \"sim_mean_%\": 84.433305485942, \"Precision\": 0.8080501150431385, \"Recall\": 0.9724697275497102, \"F1_Score\": 0.8543444890988692, \"Blue_4\": 0.7746400999589358, \"Bleu_Score_Cumulative\": 0.7846482772684893, \"Meteor_Score\": 0.24155405405405406, \"Rouge_1\": 0.895922365080103, \"Rouge_2\": 0.8997813029758835, \"Rouge_L\": 0.8952646414356874}]\n","{'shots': [1, 2, 3, 4, 5, 6, 7], 'Generated': [513, 513, 513, 513, 513, 513, 513], 'threshold': [0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95], 'samples_above_theshold': [429, 389, 362, 337, 320, 309, 296], 'sim_mean_n': [429.0, 430.0, 429.6666666666597, 428.5, 429.79999999998415, 431.83333333334747, 433.14285714288246], 'sim_mean_%': [83.62573099415205, 83.82066276803118, 83.75568551007011, 83.52826510721248, 83.78167641325227, 84.17803768681237, 84.433305485942], 'Precision': [0.9302987679880345, 0.8490551879768369, 0.8391496081148198, 0.8239332973645072, 0.8235277332086985, 0.8356702526443539, 0.8080501150431385], 'Recall': [0.9582156787537927, 0.9614639739231818, 0.9700920192087632, 0.974732250009244, 0.9800131243237701, 0.9909147217288845, 0.9724697275497102], 'F1_Score': [0.9356401444088542, 0.883846037980734, 0.8791537672184582, 0.8685071800659993, 0.8696876641735878, 0.8825329052431538, 0.8543444890988692], 'Blue_4': [0.8608706871043914, 0.802022056789912, 0.8062324613577251, 0.7920450166105034, 0.7920379980732509, 0.8116430951493884, 0.7746400999589358], 'Bleu_Score_Cumulative': [0.8833711816037341, 0.8188051699183908, 0.8190625694705936, 0.8041497607497559, 0.8042812385090181, 0.821204171304195, 0.7846482772684893], 'Meteor_Score': [0.2191142191142191, 0.2365038560411311, 0.24447513812154695, 0.2551928783382789, 0.2390625, 0.27346278317152106, 0.24155405405405406], 'Rouge_1': [0.9281387129874333, 0.9047341889793871, 0.9221275742997038, 0.9162429508855462, 0.9091443486958266, 0.91537808750923, 0.895922365080103], 'Rouge_2': [0.9176012584172245, 0.8983643222696338, 0.919369592409375, 0.9123366294427875, 0.9114370061808973, 0.9186155296872831, 0.8997813029758835], 'Rouge_L': [0.926894660927173, 0.903324957939787, 0.9216488896063387, 0.9149648048361684, 0.9072523881498528, 0.9149194573919717, 0.8952646414356874]}\n"]}]}]}