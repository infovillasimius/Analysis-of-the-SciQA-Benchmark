Questions	SPARQL in Gold Standard	SPARQL generated	Template	exact match
Which model has achieved the highest Accuracy score on the Story Cloze Test benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Story Cloze Test"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/conf/naacl/RosenbergH09> ?answer. ?x <https://dblp.org/rec/journals/corr/abs-1905-06452> ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
List the title and ID of research papers that contain a benchmark over the Penn Treebank (Word Level) dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Penn Treebank (Word Level)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'NAACL HLT'. ?x <https://dblp.org/rdf/schema#yearOfPublication> '1989'. ?x <https://dblp.org/rdf/schema#numberOfCreators> '3'. ?x <https://dblp.org/rdf/schema#numberOfCreators> ?secondanswer }	False
What models are being evaluated on the UrbanSound8k dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""UrbanSound8k"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL16> <https://dblp.org/rdf/schema#authoredBy> ?answer. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL16> <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL16#evaluatedOn> 'UrbanSound8k' }	False
Provide a list of research paper titles and IDs that have benchmarked models on the Penn Treebank dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Penn Treebank"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/ai/KuoLC00> <https://dblp.org/rec/conf/igarss/WeaverMDLH02>. ?x <https://dblp.org/rec/conf/igarss/WeaverMDLH02> ?firstanswer. ?x <https://dblp.org/rec/conf/igarss/WeaverMDLH02> ?secondanswer }	False
What is the top benchmark score and its metric on the MAZEA dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MAZEA"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer MAX( ?metric) AS ?metric WHERE { ?x score ?answer metric ?metric. ?x train_on MAZEA }	False
What models are being evaluated on the TDMSci dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""TDMSci"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/igarss/TouziPHJ19> <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#publishedIn> 'IGARSS' }	False
What is the mean capacity of a carbon-based fuel?	"SELECT (AVG( ?numerical_capacity) AS ?mean) WHERE { ?paper a orkgc:Paper; orkgp:P31 [ orkgp:P15483 ?capacity ]; rdfs:label ?title. BIND( xsd:double( REPLACE( STR( REPLACE( ?capacity, ""([0-9]+),([0-9]+)"", ""$1$2"" ) ), ""([0-9]+).*"", ""$1"" ) ) AS ?numerical_capacity ) FILTER(REGEX(STR( ?title), ""(fuel|CO2)"")) }"	SELECT (AVG( ?answer) AS ?answer) WHERE { ?x sd:meanCapacity ?answer. ?x sd:carbonBasedFuel true }	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MLDoc Zero-Shot English-to-Russian dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MLDoc Zero-Shot English-to-Russian"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/w4a/RosenbergP17>. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?firstanswer <https://dblp.org/rdf/schema#publishedIn> 'W4A'. ?thirdanswer <https://dblp.org/rec/conf/w4a/RosenbergP17>. ?thirdanswer <https://dblp.org/rdf/schema#title> ?secondanswer. ?thirdanswer <https://dblp.org/rdf/schema#yearOfPublication> '2017' }	False
Indicate the model that performed best in terms of Accuracy metric on the Kuzushiji-MNIST benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Kuzushiji-MNIST"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/eacl/TsvetkovMD14>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Which model has achieved the highest BLEU score score on the WMT2016 Romanian-English benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""BLEU score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2016 Romanian-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x compute_bleu( ?y, ?answer). ?y WMT2016_ROEN() }	False
What is the highest benchmark result achieved on the Ball in cup, catch (DMControl500k) dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Ball in cup, catch (DMControl500k)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/igarss/ChandrasekarLA14> <https://dblp.org/rdf/schema#numberOfAntennas> ?answer }	False
What is the name of the top performing model in terms of Top-1 Accuracy score when benchmarked on the VTAB-1k dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Top-1 Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""VTAB-1k"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/ChenTPLRLV20>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer } ORDER BY DESC( ?y <https://dblp.org/rdf/schema#authoredBy> ?answer) LIMIT 1	False
What are the titles and IDs of research papers that include a benchmark for the arXiv dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""arXiv"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2203-09376> ?firstanswer. ?x <https://dblp.org/rec/journals/corr/abs-2203-09376> ?secondanswer }	False
Can you list the metrics used to evaluate models on the TDM Tagged Corpus dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""TDM Tagged Corpus"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/pid/34/2497> <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#numberOfCreators> ?answer FILTER ( ?y!= <https://dblp.org/rec/journals/tdm/BenhardusK14>) }	False
Provide a list of research paper titles and IDs that have benchmarked models on the BC5CDR-disease dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BC5CDR-disease"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2007-00936> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?y <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?y <https://dblp.org/rdf/schema#yearOfPublication> ?secondanswer. ?x <https://dblp.org/rdf/schema#yearOfPublication> ?secondanswer FILTER ( ?y!= ?x) }	False
What is the name of the top performing model in terms of Score score when benchmarked on the Lunar Lander (OpenAI Gym) dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Lunar Lander (OpenAI Gym)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://www.openai.com/api/v1/embedded/luna/Score> ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
What evaluation metrics are commonly used when benchmarking models on the FSNS - Test dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""FSNS - Test"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/pid/99/3994> <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#publishedIn> 'FSNS - Test'. ?y <https://dblp.org/rdf/schema#yearOfPublication> ?z. ?y <https://dblp.org/rdf/schema#evaluatedBy> ?answer FILTER ( ?x!= ?y) FILTER ( ?x!= ?z) }	False
What are the titles and IDs of research papers that include a benchmark for the ImageNet 64x64 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ImageNet 64x64"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/iclr/0001C0USLZ20> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'ICLR'. ?x <https://dblp.org/rdf/schema#title> ?secondanswer. ?secondanswer <https://dblp.org/rdf/schema#mention> 'ImageNet 64x64' }	False
What are the metrics of evaluation over the Classical music, 5 seconds at 12 kHz dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Classical music, 5 seconds at 12 kHz"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icassp/ElizaldeKSB12>. ?x < ?answer> ?answer_value }	False
Provide a list of papers that have utilized the Flair-TDM model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Flair-TDM"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/ai/KimLJ07>. ?firstanswer <https://dblp.org/rec/conf/naacl/LiCJ19>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-1805-06350>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91>. ?firstanswer <https://dblp.org/rec/journals/tvt/XuSWWL15>. ?firstanswer <https://dblp.org/rec/conf/igarss/WeaverMD03>. ?firstanswer <https://dblp.org/rec/conf/icassp/ZhouV11>. ?firstanswer <https://dblp.org/rec/conf/igarss/WyniawskyjGDBM19>. ?firstanswer <https://dblp.org/rec/conf/igarss/WeaverMD04>. ?firstanswer <https://dblp.org/rec/journals/ijahuc/LuWCL09>. ?firstanswer <https://dblp.org/rec/conf/icassp/ZhouV11>. ?firstanswer <https://dblp.org/rec/conf/icassp/ZhouV11>. ?firstanswer <https://dblp.org/rec/conf/igarss/WeaverMD03>. ?firstanswer <https://dblp.org/rec/conf/igarss/WeaverMD04>. ?firstanswer <https://dblp.org/rec/conf/igarss/WyniawskyjGDBM19>. ?firstanswer <https://dblp.org/rec/journals/ai/KimLJ07>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91>. ?firstanswer <https://dblp.org/rec/journals/tvt/XuSWWL15>. ?firstanswer <https://dblp.org/rec/conf/naacl/LiCJ19>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-1805-06350>. ?firstanswer <https://dblp.org/rec/conf/igarss/WeaverMD03>. ?firstanswer <https://dblp.org/rec/conf/igarss/WeaverMD04>. ?firstanswer <https://dblp.org/rec/conf/igarss/WyniawskyjGDBM19>. ?firstanswer <https://dblp.org/rec/journals/ai/KimLJ07>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91>. ?firstanswer <https://dblp.org/rec/journals/tvt/XuSWWL15>. ?firstanswer <https://dblp.org/rec/conf/naacl/LiCJ19>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-1805-06350>. ?firstanswer <https://dblp.org/rec/conf/igarss/WeaverMD03>. ?firstanswer <https://dblp.org/rec/conf/igarss/WeaverMD04>. ?firstanswer <https://dblp.org/rec/conf/igarss/WyniawskyjGDBM19>. ?firstanswer <https://dblp.org/rec/journals/ai/KimLJ07>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91>. ?firstanswer <https://dblp.org/rec/journals/tvt/XuSWWL15>. ?firstanswer <https://dblp.org/rec/conf/naacl/LiCJ19>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-1805	False
Can you provide links to code used in papers that benchmark the Transformer-XL Base model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Transformer-XL Base"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/pid/99/3994> <https://dblp.org/rec/journals/corr/abs-1901-03788>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the best performing model benchmarking the BUCC German-to-English dataset in terms of F1 score metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1 score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BUCC German-to-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/mta/BucciaGLA19> ?answer. ?x <https://dblp.org/rec/journals/mta/BucciaGLA19> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of papers that have utilized the SAN (single) model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""SAN (single)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/igarss/DoubkovaH06>. ?firstanswer <https://dblp.org/rec/journals/ijgi/BelussiME20>. ?firstanswer <https://dblp.org/rec/conf/icassp/ZhouV11>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2006-11781>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2004-09494>. ?firstanswer <https://dblp.org/rec/conf/IEEEwisa/XuXOEX18>. ?firstanswer <https://dblp.org/rec/journals/jcam/ChengDL22>. ?firstanswer <https://dblp.org/rec/conf/icira/ChaiC08>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiGZGZL18>. ?firstanswer <https://dblp.org/rec/conf/icira/LiG	False
What are the models that have been benchmarked on the ACE 2005 dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ACE 2005"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/mta/HafidhOKAE14>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Where can I find code references in papers that have used the PNDec model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""PNDec"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2107-12425>. ?x < ?answer> }	False
Where can I find code references in papers that have used the CATTS-XSUM model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""CATTS-XSUM"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/ChurchGHH89>. ?x < ?answer> ?y }	False
What is the top benchmark result (metric and value) over the dataset IMDb-B?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""IMDb-B"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcai/ShekharD89> <https://dblp.org/rdf/schema#authoredBy> ?answer. ?x <https://dblp.org/rdf/schema#publishedIn> 'IMDb-B' }	False
What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot German-to-French?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MLDoc Zero-Shot German-to-French"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/Kruijff-KorbayovaRKE03> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Where can I find code references in papers that have used the SemExp model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""SemExp"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/KliegrBF21>. ?x < ?answer> ?answerValue }	False
What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Up and Down dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Up and Down"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91> ?answer }	False
What is the name of the top performing model in terms of Number of params score when benchmarked on the Penn Treebank (Character Level) dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Number of params"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Penn Treebank (Character Level)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x service: 'Penn Treebank (Character Level)' ?x model: ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
Provide a list of research paper titles and IDs that have benchmarked models on the Penn Treebank (Character Level) dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Penn Treebank (Character Level)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rec/journals/tip/ChangY09> <https://dblp.org/rec/journals/csda/Chen04> <https://dblp.org/rec/journals/ieicet/HasegawaS11> <https://dblp.org/rec/journals/tbe/MatsuokaRAM01> <https://dblp.org/rec/journals/ijbc/KuznetsovS19> <https://dblp.org/rec/conf/igarss/WeaverMDL02> <https://dblp.org/rec/conf/icassp/ElkhalilK0AA20> <https://dblp.org/rec/conf/medinfo/KuballaSMGN11> <https://dblp.org/rec/conf/IEEEicci/ZouZZL19> <https://dblp.org/rec/journals/ijcomsys/PangLJ09> <https://dblp.org/rec/journals/ijbc/KuznetsovS19> <https://dblp.org/rec/journals/ijbc/KuznetsovS19> <https://dblp.org/rec/conf/igarss/WeaverMDL02> <https://dblp.org/rec/conf/igarss/WeaverMDL02> <https://dblp.org/rec/conf/icassp/ElkhalilK0AA20> <https://dblp.org/rec/conf/icassp/ElkhalilK0AA20> <https://dblp.org/rec/conf/medinfo/KuballaSMGN11> <https://dblp.org/rec/conf/medinfo/KuballaSMGN11> <https://dblp.org/rec/conf/IEEEicci/ZouZZL19> <https://dblp.org/rec/conf/IEEEicci/ZouZZL19> <https://dblp.org/rec/journals/ijcomsys/PangLJ09> <https://dblp.org/rec/journals/ijcomsys/PangLJ09> }	False
What are the metrics of evaluation over the Atari 2600 Double Dunk dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Double Dunk"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://sciqa.org/datasets/Atari2600DoubleDunk> <https://sciqa.org/rdf/schema#metricsOfEvaluation> ?answer }	False
Which model has achieved the highest Top 1 Accuracy score on the ImageNet V2 benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Top 1 Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ImageNet V2"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x ycsb:Top1Accuracy ?answer. ?x ycsb:Dataset 'ImageNet V2' }	False
What is the most common Knowledge representation method?	SELECT (COUNT( ?repr) AS ?cnt) ?repr WHERE { orkgr:R8364 orkgp:compareContribution ?cont. ?cont orkgp:P7046 ?sys. ?sys orkgp:P7056 ?repr. } GROUP BY ?repr ORDER BY DESC( ?cnt) LIMIT 1	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x ?y ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
Where can all the data sets used in the compared studies be found?	"SELECT DISTINCT ?URL WHERE { orkgr:R112387 orkgp:compareContribution ?contrib. ?contrib orkgp:HAS_DATASET ?URL. FILTER(!REGEX( ?URL, ""Not"")) }"	SELECT DISTINCT ?answer WHERE { { <https://doi.org/10.1007/s00192-015-0449-7> <https://dblp.org/rec/journals/ijar/PalBH93>. <https://doi.org/10.1007/s00192-015-0449-7> < ?answer>. <https://dblp.org/rec/journals/ijar/PalBH93> < ?answer> } UNION { <https://doi.org/10.1007/s00192-015-0449-7> <https://dblp.org/rec/journals/ijar/PalBH93>. <https://dblp.org/rec/journals/ijar/PalBH93> < ?answer> }	False
What are the most commonly used benchmark datasets for the Entity Disambiguation research field?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Entity Disambiguation"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/conf/eacl/PinchakL06> ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 10	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the BIOSSES dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BIOSSES"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/corr/abs-2107-12425>. ?firstanswer <https://dblp.org/rdf/schema#title> ?secondanswer. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?thirdanswer }	False
Which model has achieved the highest F1 score score on the BUCC Chinese-to-English benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1 score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BUCC Chinese-to-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x buccChineseToEnglish( ?answer) }	False
Provide a list of research paper titles and IDs that have benchmarked models on the ImageNet ReaL dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ImageNet ReaL"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/icra/J\u00E4kelmCCD15>. ?x <https://dblp.org/rec/conf/icra/J\u00E4kelmCCD15>. }	False
What are the titles and IDs of research papers that include a benchmark for the Gibson PointGoal Navigation dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Gibson PointGoal Navigation"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/robotica/ZhangK18>. ?x <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'Robotica'. ?y <https://dblp.org/rec/journals/robotica/ZhangK18>. ?y <https://dblp.org/rdf/schema#title> ?secondanswer }	False
What is the top benchmark result (metric and value) over the dataset CoNLL++?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CoNLL++"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/conll/CarrerasMP02>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the best performing model benchmarking the PIQA dataset in terms of Accuracy metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""PIQA"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/MurakamiT15> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of Score metric on the Atari 2600 Crazy Climber benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Crazy Climber"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2106-03731>. ?x <https://dblp.org/rdf/schema#Score> ?answer }	False
Provide a list of papers that have utilized the Table-Sequence model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Table-Sequence"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rec/journals/tcom/Panayirci93> <https://dblp.org/rec/journals/corr/abs-2105-09666> <https://dblp.org/rec/conf/icra/JoukhadarL95> <https://dblp.org/rec/conf/igarss/MarpuGC10> <https://dblp.org/rec/conf/IEEEwisa/XuXSW017> <https://dblp.org/rec/journals/ijcga/DehkordiE12> <https://dblp.org/rec/conf/iscas/MagramA94> <https://dblp.org/rec/conf/IEEEicci/ZouZZL19> <https://dblp.org/rec/journals/corr/abs-2102-06388> <https://dblp.org/rec/journals/trob/Ben-GharbiaMR13> <https://dblp.org/rec/conf/icra/RekleitisLNC04> <https://dblp.org/rec/conf/siggraph/Thompson14> <https://dblp.org/rec/conf/iccd/Kadi41> <https://dblp.org/rec/conf/hci/TanakaKN97> <https://dblp.org/rec/conf/IEEEicci/ZouZZL19> <https://dblp.org/rec/conf/igarss/MarpuGC10> <https://dblp.org/rec/conf/IEEEwisa/XuXSW017> <https://dblp.org/rec/conf/iscas/MagramA94> <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rec/journals/corr/abs-2105-09666> <https://dblp.org/rec/conf/icra/JoukhadarL95> <https://dblp.org/rec/journals/ijcga/DehkordiE12> <https://dblp.org/rec/conf/IEEEicci/ZouZZL19> <https://dblp.org/rec/conf/igarss/MarpuGC10> <https://dblp.org/rec/conf/IEEEwisa/XuXSW017> <https://dblp.org/rec/conf/iscas/MagramA94> <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rec/journals/corr/abs-2105-09666> <https://dblp.org/rec/conf/icra/JoukhadarL95> <https://dblp.org/rec/journals/ijcga/DehkordiE12> <https://dblp.org/rec/conf/IEEEicci/ZouZZL19> <https://dblp.org/rec/conf/igarss/MarpuGC10> <https://dblp.org/rec/conf/IEEEwisa/XuXSW017> <https://dblp.org/rec/conf/iscas/MagramA94> <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rec/journals/corr/abs-2105-09666> <https://dblp.org/rec/conf/icra/JoukhadarL95> <https://dblp.org/rec/journals/ijcga/DehkordiE12> <https://dblp.org/rec/conf/IEEEicci/ZouZZL19> <https://dblp.org/rec/conf/igarss/MarpuGC10> <https://dblp.org/rec/conf/IEEEwisa/XuXSW017> <https://dblp.org/rec/conf/iscas/MagramA94> <https://dblp.org/rec/conf/naacl/LiCZY16> <https://db	False
Provide a list of papers that have utilized the Funnel Transformer model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Funnel Transformer"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/icassp/MaduenoB21>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2012-12094>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2205-12506>. ?secondanswer <https://dblp.org/rec/journals/corr/abs-2012-12094>. ?secondanswer <https://dblp.org/rec/journals/corr/abs-2205-12506> }	False
What evaluation metrics are commonly used when benchmarking models on the Reuters De-En dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Reuters De-En"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1909-09938> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of F1 metric on the PubMed 20k RCT benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""PubMed 20k RCT"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2203-15634>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the code links in papers that use the DocRED-BiLSTM model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""DocRED-BiLSTM"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the best performing model benchmarking the Oxford-IIIT Pets dataset in terms of FLOPS metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""FLOPS"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Oxford-IIIT Pets"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/cogsci/ZhaoPRS18> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the top benchmark result (metric and value) over the dataset AESLC?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""AESLC"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iscas/AkihoTHK00> ?answer. ?x <https://dblp.org/rdf/schema#metric> ?answer. ?x <https://dblp.org/rdf/schema#value> ?answer }	False
What are the titles and IDs of research papers that include a benchmark for the Oxford-IIIT Pets dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Oxford-IIIT Pets"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/cvpr/ZhengJ13>. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2013'. ?x <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'CVPR'. ?y <https://dblp.org/rec/conf/cvpr/GdalyahuWS16>. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?y <https://dblp.org/rdf/schema#publishedIn> 'CVPR' }	False
What is the top benchmark score and its metric on the WOS-46985 dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WOS-46985"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer_max MIN( ?answer) AS ?answer_min WHERE { <WOS-46985> <https://dblp.org/rec/conf/icassp/GlassHH99> ?answer }	False
Provide a list of papers that have utilized the AcrE model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""AcrE"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://sciq.org/schema#acrE>. ?firstanswer <https://sciq.org/schema#code> ?secondanswer }	False
What is the best performing model benchmarking the Supervised: dataset in terms of SemEval 2013 metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""SemEval 2013"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Supervised:"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/journals/mta/HafidhOKAE14> <https://dblp.org/rdf/schema#authoredBy> ?x. <https://dblp.org/rec/journals/mta/HafidhOKAE14> <https://dblp.org/rdf/schema#publishedIn> 'Math. Comput. Simul.'. ?y <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#publishedIn> 'Math. Comput. Simul.'. ?y <https://dblp.org/rdf/schema#yearOfPublication> ?answer FILTER ( ?answer > <https://dblp.org/rec/journals/mta/HafidhOKAE14> <https://dblp.org/rdf/schema#yearOfPublication>) }	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SciERC dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SciERC"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/corr/abs-1905-06452>. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?firstanswer <https://dblp.org/rdf/schema#publishedIn> ?thirdanswer }	False
What quantity of iron oxide was discovered on Elorza crater?	"SELECT ?properties_values, ?property_description WHERE { ?papers rdf:type orkgc:Paper. ?papers rdfs:label ?papers_labels. FILTER(REGEX( ?papers_labels, ""Elorza crater"", ""i"")) ?papers orkgp:P31 ?contrib. ?contrib ?properties ?properties_values. ?properties rdfs:label ?properties_labels. FILTER(REGEX( ?properties_labels, ""FeO"")) ?properties orkgp:description ?property_description. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ijcomsys/JanicM06>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you list the models that have been evaluated on the VTAB-1k dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""VTAB-1k"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x model: ?answer. ?x eval: 'VTAB-1k' }	False
Provide a list of papers that have utilized the DQN-PixelCNN model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""DQN-PixelCNN"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/iscas/SamadianHA03> <https://dblp.org/rec/conf/icra/AckermanCC14> <https://dblp.org/rec/journals/corr/abs-1902-08463> <https://dblp.org/rec/conf/icnn/ThomeT99> <https://dblp.org/rec/conf/icdsp2/LinLH20> <https://dblp.org/rec/journals/tog/WolperW03> <https://dblp.org/rec/journals/ijbc/AllioC10> <https://dblp.org/rec/journals/corr/abs-1905-06452> <https://dblp.org/rec/conf/medinfo/KuballaSMTH19> <https://dblp.org/rec/journals/corr/abs-1907-02121> <https://dblp.org/rec/conf/ijcnn/YehCJH15> <https://dblp.org/rec/conf/cdc/Rueda-EscobedoM15> <https://dblp.org/rec/conf/iros/LisienMSKRC03> <https://dblp.org/rec/conf/iecon/ZhenmanY17> <https://dblp.org/rec/conf/cvpr/AzarbayejaniHP93> <https://dblp.org/rec/conf/hci/FischerK17> <https://dblp.org/rec/conf/iecon/ZhenmanY18> <https://dblp.org/rec/conf/infocom/FanWJXZ20> <https://dblp.org/rec/conf/IEEEants/AzizHZ10> <https://dblp.org/rec/journals/corr/abs-1909-08303> <https://dblp.org/rec/journals/corr/abs-1904-03743> <https://dblp.org/rec/conf/icdsp/LinLH20> <https://dblp.org/rec/conf/icicic/ZhangNZLL06> <https://dblp.org/rec/journals/corr/abs-1907-05702> <https://dblp.org/rec/conf/icdsp2/LinLH20> <https://dblp.org/rec/conf/IEEEants/AzizHZ10> <https://dblp.org/rec/journals/corr/abs-1909-08303> <https://dblp.org/rec/conf/infocom/FanWJXZ20> <https://dblp.org/rec/conf/icicic/ZhangNZLL06> <https://dblp.org/rec/conf/icra/AckermanCC14> <https://dblp.org/rec/journals/corr/abs-1902-08463> <https://dblp.org/rec/conf/icnn/ThomeT99> <https://dblp.org/rec/conf/iscas/SamadianHA03> <https://dblp.org/rec/conf/medinfo/KuballaSMTH19> <https://dblp.org/rec/journals/corr/abs-1907-02121> <https://dblp.org/rec/conf/ijcnn/YehCJH15> <https://dblp.org/rec/conf/cdc/Rueda-EscobedoM15> <https://dblp.org/rec/conf/iros/LisienMSKRC03> <https://dblp.org/rec/conf/iecon/ZhenmanY17> <https://dblp.org/rec/conf/cvpr/AzarbayejaniHP93> <https://dblp.org/rec/conf/hci/FischerK17> <https://dblp.org/rec/conf/iecon/ZhenmanY18> <https://dblp.org/rec/conf/infocom/FanWJXZ20> <https://dblp.org/rec/conf/IEEEants/Az	False
Can you list the metrics used to evaluate models on the Atari 2600 Freeway dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Freeway"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://sciqa.org/datasets/Atari2600Freeway> <https://sciqa.org/rdf/schema#metrics> ?answer }	False
List the code links in papers that use the Dynamic Coattention Networks (single model) model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Dynamic Coattention Networks (single model)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/KimH17> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of Macro Precision metric on the NLP-TDMS (Exp, arXiv only) benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Macro Precision"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/Kass86>. ?x < ?answer> ?y. ?z <https://dblp.org/rec/journals/ai/Kass86>. ?z < ?answer> ?y FILTER ( ?x!= ?z) }	False
What is the top benchmark score and its metric on the Atari 2600 Tennis dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Tennis"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(x) AS max_score, y AS metric WHERE { ?x ?y ?z. ?z 'Tennis' }	False
What are the metrics of evaluation over the DuIE dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""DuIE"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/pid/47/10537> <https://dblp.org/rec/conf/duie/ChenLGZ20> ?answer }	False
List the metrics that are used to evaluate models on the Cheetah, run (DMControl500k) benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Cheetah, run (DMControl500k)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://sciqa.org/benchmarks/DMControl500k> <https://sciqa.org/rdf-schema#metrics> ?answer }	False
Could you provide a list of models that have been tested on the Reuters RCV1/RCV2 English-to-German benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Reuters RCV1/RCV2 English-to-German"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/tcom/ParkLM18> ?answer. ?y <https://dblp.org/rec/journals/tcom/ParkLM18> ?answer FILTER ( ?y!= ?x) }	False
What types of nanocarriers do have therapeutic effect?	"SELECT ?types_of_nanocarriers, ?types_of_nanocarriers_labels WHERE { orkgr:R144364 orkgp:compareContribution ?contrib. ?contrib orkgp:P41740 ?types_of_nanocarriers. ?contrib orkgp:P41743 ?therapeutic_effect. FILTER( ?therapeutic_effect = ""T""^^xsd:string) ?types_of_nanocarriers rdfs:label ?types_of_nanocarriers_labels. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/apsit/LalwaniM15> ?answer. ?x <https://dblp.org/rec/journals/apsit/LalwaniM15> <https://dblp.org/rdf/schema#therapeuticEffect> 'true' }	False
What is the name of the top performing model in terms of ROUGE-2 score when benchmarked on the CL-SciSumm dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""ROUGE-2"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CL-SciSumm"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x ?y ?answer. ?x ?z 'CL-SciSumm'. ?x ?z ?answer FILTER( ?y = 'ROUGE-2') GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1 }	False
List the code links in papers that use the Unsupervised NMT + weight-sharing model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Unsupervised NMT + weight-sharing"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/wnmt/HasanBA19> ?answer. ?x <https://dblp.org/rec/conf/wnmt/HasanBA19> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Which model has achieved the highest Permuted Accuracy score on the Sequential MNIST benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Permuted Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Sequential MNIST"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x permutedAccuracy ?answer. ?x dataSet 'Sequential MNIST' }	False
Can you list the models that have been evaluated on the SciTLDR dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SciTLDR"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2007-14050> ?answer. ?x <https://dblp.org/rec/journals/corr/abs-2007-14050> ?y FILTER ( ?y!= ?answer) }	False
List the metrics that are used to evaluate models on the CommonsenseQA benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CommonsenseQA"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/MurphyR10> ?answer. ?y <https://dblp.org/rec/journals/ai/MurphyR10> ?answer FILTER ( ?y!= ?x) }	False
What is the highest benchmark result achieved on the IMDb-M dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""IMDb-M"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x IMDb-M ?y. ?x ?answer ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the Scholarly entity usage detection dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Scholarly entity usage detection"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/journals/firstmonday/Nevarez06>. ?x <https://dblp.org/rdf/schema#authoredBy> ?y. ?y <https://dblp.org/rdf/schema#webpage> ?z. BIND( ?z AS ?answer) }	False
Can you list the models that have been evaluated on the MultiNLI dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MultiNLI"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x evaluatedOn MultiNLI ?answer }	False
List the metrics that are used to evaluate models on the 200k Short Texts for Humor Detection benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""200k Short Texts for Humor Detection"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/igarss/DoubkovaH06> ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the Sequential MNIST dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Sequential MNIST"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x svmscale 1.0. ?x svmbias -0.5. ?x svmmakelearnable true. ?x svmkerneltype 'rbf'. ?x svminput 'Sequential MNIST'. ?x svmrounding 'half'. ?x svmresult ?answer }	False
Provide a list of papers that have utilized the CRF with sentence expansion model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""CRF with sentence expansion"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/ai/KobayashiU17>. ?secondanswer <https://dblp.org/rec/journals/ai/KobayashiU17>. }	False
What is the top benchmark result (metric and value) over the dataset NYT-single?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NYT-single"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/sciqa/AllisonKD16>. ?x ?answer }	False
List the metrics that are used to evaluate models on the SciTLDR benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SciTLDR"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/Moosavi15> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you list the models that have been evaluated on the WMT2016 English-German dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2016 English-German"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x eval: ?answer. ?x WMT2016: English-German }	False
Indicate the model that performed best in terms of FLOPS metric on the CIFAR-100 benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""FLOPS"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CIFAR-100"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icml/Ortiz-JimenezMF17>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the top benchmark result (metric and value) over the dataset RotoWire (Relation Generation)?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""RotoWire (Relation Generation)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ton/QianL16> ?answer. ?y <https://dblp.org/rec/journals/ton/QianL16> ?answer FILTER ( ?y!= ?x) }	False
What is the best performing model benchmarking the Reacher, easy (DMControl100k) dataset in terms of Score metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Reacher, easy (DMControl100k)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2006-07937> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you list the models that have been evaluated on the Atari 2600 Assault dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Assault"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x model: ?answer. ?x evaluation: ?y. ?y dataset: 'Assault' }	False
Where can I find code references in papers that have used the DQNMMCe+SR model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""DQNMMCe+SR"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/semweb/VerhaegRH21> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the Ball in cup, catch (DMControl100k) dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Ball in cup, catch (DMControl100k)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1911-09890>. ?x <https://dblp.org/rdf/schema#metric> ?answer }	False
What is the name of the top performing model in terms of F1 score when benchmarked on the NYT-single dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NYT-single"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x ?y ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
Can you provide links to code used in papers that benchmark the MEMEN (single model) model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""MEMEN (single model)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/braininf/HeHWY21> ?answer }	False
Provide a list of papers that have utilized the MMV TSM-50x2 model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""MMV TSM-50x2"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/corr/abs-2006-11438>. ?secondanswer <https://dblp.org/rec/journals/corr/abs-2006-11438>. }	False
Which model has achieved the highest Accuracy score on the Yelp-5 benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Yelp-5"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x yelpstars:rating 5. ?x yelpstars:model ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
What is the best performing model benchmarking the WMT2016 German-English dataset in terms of BLEU score metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""BLEU score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2016 German-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/wmt/BechdelfMBT16> ?answer. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of papers that have utilized the SAC model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""SAC"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/sac/AraujoRPB16>. ?firstanswer <https://dblp.org/rec/conf/sac/AraujoRPB16> ?secondanswer }	False
Provide a list of papers that have utilized the MEMEN model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""MEMEN"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://sciq.org/schema#utilizedBy> <https://sciq.org/schema#MEMEN>. ?firstanswer <https://sciq.org/schema#code> ?secondanswer }	False
Where can I find code references in papers that have used the Past Decode Reg. + AWD-LSTM-MoS + dyn. eval. model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Past Decode Reg. + AWD-LSTM-MoS + dyn. eval."") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/chiir/Al-HarbiS16> ?answer. ?x <https://dblp.org/rdf/schema#authoredBy> ?y. ?y <https://dblp.org/rdf/schema#primaryAffiliation> 'King Abdulaziz University, Jeddah, Saudi Arabia' }	False
What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Assault dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Assault"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2004-05913> ?answer. ?x <https://dblp.org/rec/journals/corr/abs-2004-05913> <https://dblp.org/rdf/schema#Score> ?count } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
What is the best performing model benchmarking the 200k Short Texts for Humor Detection dataset in terms of F1-score metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1-score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""200k Short Texts for Humor Detection"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/igarss/MertensBVW04>. ?x <https://dblp.org/rec/journals/ijgi/BelussiME20>. ?answer <https://dblp.org/rdf/schema#metric> 'F1-score'. ?x <https://dblp.org/rdf/schema#performance> ?answer }	False
Where can I find code references in papers that have used the STREET model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""STREET"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1807-04687>. ?x < ?answer> ?y }	False
Can you list the models that have been evaluated on the enwiki8 dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""enwiki8"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x model: ?answer. ?x eval: enwiki8 }	False
Provide a list of research paper titles and IDs that have benchmarked models on the SciERC dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SciERC"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'	False
Indicate the model that performed best in terms of Accuracy metric on the CommonsenseQA benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CommonsenseQA"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/LinL05>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What evaluation metrics are commonly used when benchmarking models on the SQuAD2.0 dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SQuAD2.0"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/ChengDZ15> ?answer. ?y <https://dblp.org/rec/journals/corr/ChenHXW17> ?answer FILTER ( ?y!= ?x) }	False
What evaluation metrics are commonly used when benchmarking models on the WMT2014 English-German dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2014 English-German"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2203-09246> ?answer }	False
Provide a list of benchmarked datasets related to the Reading Comprehension research area?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Reading Comprehension"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/LeeCDD16> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Which model has achieved the highest RE+ Micro F1 score on the CoNLL04 benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""RE+ Micro F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CoNLL04"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x ref_model ?answer. ?x evaluated_on 'CoNLL04' }	False
Provide a list of papers that have utilized the XLNet (base) model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""XLNet (base)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/iclr/ChenDXGK20> <https://dblp.org/rec/conf/iclr/DelmonteT19> <https://dblp.org/rec/journals/ai/Verheij00> <https://dblp.org/rec/conf/ijcai/ShekharD89> }	False
List the title and ID of research papers that contain a benchmark over the Ohsumed dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Ohsumed"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/igarss/OnrubiaGPPQAC15> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'IGARSS'. ?y <https://dblp.org/rec/conf/medinfo/KuballaSMGN19> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?y <https://dblp.org/rdf/schema#publishedIn> 'MEDINFO (1)' }	False
Could you provide a list of models that have been tested on the NYT29 benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NYT29"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x NYT29:testedOn ?answer }	False
Which are 3 the most common variables for the atmosphere models?	"SELECT ?variables WHERE { orkgr:R68871 orkgp:compareContribution ?contrib. ?contrib orkgp:P7144 ?models. ?models rdfs:label ?models_labels. FILTER(REGEX( ?models_labels, ""tmospher"")) ?models orkgp:P26032 ?variables. } ORDER BY DESC(COUNT( ?variables)) LIMIT 3"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/conf/ictc/0003GL10> ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 3	False
List the code links in papers that use the DDQN-PC model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""DDQN-PC"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2006-15036> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the title and ID of research papers that contain a benchmark over the TREC-6 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""TREC-6"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/naacl/RosenbergH09> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2009'. ?x <https://dblp.org/rdf/schema#title> ?firstanswer. ?x <https://dblp.org/rdf/schema#id> ?secondanswer }	False
Can you provide links to code used in papers that benchmark the Rational DQN Average model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Rational DQN Average"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/DoyleSTL19> ?answer. ?x <https://dblp.org/rec/conf/iclr/DoyleSTL19> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the name of the top performing model in terms of Accuracy score when benchmarked on the MLDoc Zero-Shot English-to-French dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MLDoc Zero-Shot English-to-French"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x ?y ?answer. ?x ?y ?count } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
Indicate the model that performed best in terms of 1-of-100 Accuracy metric on the PolyAI Reddit benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""1-of-100 Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""PolyAI Reddit"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/polyai/HasanZ21> ?answer }	False
List the code links in papers that use the Long Short Transformer model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Long Short Transformer"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/SmithBFPRNWA21> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the name of the top performing model in terms of Accuracy score when benchmarked on the TriviaQA dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""TriviaQA"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x TriviaQA ?answer ?count } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
What is Raman spectroscopy?	"SELECT ?definitions WHERE { ?terms orkgp:P24009 ?definitions. ?terms rdfs:label ?terms_labels. FILTER(REGEX( ?terms_labels, ""Raman spectroscopy"")) }"	SELECT DISTINCT ?answer WHERE { ?answer <https://dblp.org/rec/journals/ijon/RizviC20> 'Raman spectroscopy' }	False
Can you provide the highest benchmark result, including the metric and score, for the DTD dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""DTD"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x DTD:answer ?answer }	False
What is the top benchmark score and its metric on the CINIC-10 dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CINIC-10"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer_max MIN( ?answer) AS ?answer_min WHERE { SELECT DISTINCT ?answer ( ?metric) AS ?answer_metric WHERE { ?x ?answer ?answer_metric. ?x cinic-10 } }	False
What are the titles and IDs of research papers that include a benchmark for the SemEval-2018 Task 7 dataset dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SemEval-2018 Task 7 dataset"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/sigdial/Lee14>. ?x <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#id> ?secondanswer }	False
List the metrics that are used to evaluate models on the AG News benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""AG News"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1810-02685> ?answer }	False
What is the name of the top performing model in terms of F1 entity level score when benchmarked on the NCBI Disease dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1 entity level"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NCBI Disease"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/journals/ton/QianL16> ?answer. ?y <https://dblp.org/rec/journals/ton/QianL16> ?answer FILTER ( ?y!= ?x) } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
Provide a list of research paper titles and IDs that have benchmarked models on the NCBI-disease dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NCBI-disease"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/semweb/VerhaegRH21> <https://dblp.org/rec/conf/semweb/presentations/VerhaegRH21>. ?x <https://dblp.org/rec/conf/semweb/VerhaegRH21> <https://dblp.org/rec/journals/bmcbi/EichnerBGDS15>. ?y <https://dblp.org/rec/conf/semweb/presentations/VerhaegRH21> <https://dblp.org/rec/journals/bmcbi/EichnerBGDS15>. ?y <https://dblp.org/rec/conf/semweb/presentations/VerhaegRH21> <https://dblp.org/rec/conf/semweb/VerhaegRH21> FILTER ( ?y!= ?x) }	False
Can you provide links to code used in papers that benchmark the GCN Hybrid model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""GCN Hybrid"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/0001C0USLZ20> ?answer. ?x <https://dblp.org/rec/journals/tvt/XuSWWL18> ?answer FILTER ( ?x!= <https://dblp.org/rec/conf/iclr/0001C0USLZ20>) FILTER ( ?x!= <https://dblp.org/rec/journals/tvt/XuSWWL18>) }	False
What data format does CHEMDNER corpus have?	SELECT ?data_format, ?data_format_label WHERE { orkgr:R150596 orkgp:P31 ?contrib. ?contrib orkgp:P42011 ?data_format. ?data_format rdfs:label ?data_format_label. }	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/journals/asc/WangLCDJ19> ?answer }	False
What are the titles and IDs of research papers that include a benchmark for the CUB-200-2011 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CUB-200-2011"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/icassp/ChenS11>. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?secondanswer }	False
Can you provide links to code used in papers that benchmark the SEE model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""SEE"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/semweb/VerhaegRH21>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of papers that have utilized the Duel hs model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Duel hs"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/naacl/LeeH06>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2004-06047>. ?firstanswer <https://dblp.org/rec/journals/twc/WuLSM14>. ?firstanswer <https://dblp.org/rec/journals/ijcon/ToivonenTA07>. ?firstanswer <https://dblp.org/rec/conf/icra/ZhangK14>. ?firstanswer <https://dblp.org/rec/journals/tvt/ZhouLJ13>. ?firstanswer <https://dblp.org/rec/journals/soco/WangSL19>. ?firstanswer <https://dblp.org/rec/journals/ijon/ChenLW15>. ?firstanswer <https://dblp.org/rec/conf/cdc/PrachTB14>. ?firstanswer <https://dblp.org/rec/conf/ijcai/BolesHH83>. ?firstanswer <https://dblp.org/rec/journals/ijon/ChenZLLW19>. ?firstanswer <https://dblp.org/rec/conf/iecon/ZhenYLT16>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-1806-00416>. ?firstanswer <https://dblp.org/rec/journals/tvt/XuJXG15>. ?firstanswer <https://dblp.org/rec/conf/cogsci/DeyneNCP21>. ?firstanswer <https://dblp.org/rec/conf/ijcai/ShekharD89>. ?firstanswer <https://dblp.org/rec/conf/iecon/ZhenYLT16>. ?firstanswer <https://dblp.org/rec/conf/icra/ParkL03>. ?firstanswer <https://dblp.org/rec/conf/IEEEwisa/XuXLG18>. ?firstanswer <https://dblp.org/rec/conf/cogsci/DeyneNCP21>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/icnn/SwetsW97>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec/conf/ijcai/ShekharD89>. ?firstanswer <https://dblp.org/rec/conf/cdc/PrachTB14>. ?firstanswer <https://dblp.org/rec/journals/ijon/ChenLW15>. ?firstanswer <https://dblp.org/rec/journals/soco/WangSL19>. ?firstanswer <https://dblp.org/rec/journals/tvt/ZhouLJ13>. ?firstanswer <https://dblp.org/rec/conf/icra/ZhangK14>. ?firstanswer <https://dblp.org/rec/journals/ijcon/ToivonenTA07>. ?firstanswer <https://dblp.org/rec/journals/twc/WuLSM14>. ?firstanswer <https://dblp.org/rec/conf/naacl/LeeH06>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2004-06047>. ?firstanswer <https://dblp.org/rec/conf/ijcai/BolesHH83>. ?firstanswer <https://dblp.org/rec/journals/ijon/Ch	False
What is the top benchmark result (metric and value) over the dataset DocRED (Human-annotated)?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""DocRED (Human-annotated)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/sensors/ZangeneAN21>. ?x ?answer }	False
Provide a list of papers that have utilized the Adaptive Input Large model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Adaptive Input Large"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/naacl/LiCZY16>. ?secondanswer <https://dblp.org/rec/journals/tip/ChangY09> }	False
What models are being evaluated on the Atari 2600 Solaris dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Solaris"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iccS/AlYahyaR16> ?answer. ?x <https://dblp.org/rec/journals/ijon/LiuZ21b> ?answer }	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SNLI dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SNLI"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/corr/abs-1808-01673>. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?firstanswer <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?firstanswer <https://dblp.org/rdf/schema#title> ?thirdanswer. ?x <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?x <https://dblp.org/rdf/schema#title> ?thirdanswer FILTER ( ?x!= <https://dblp.org/rec/journals/corr/abs-1808-01673>) }	False
Where can I find code references in papers that have used the MMV model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""MMV"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icmv/RosalesC18>. ?x < ?answer> ?answerValue }	False
What is the top benchmark score and its metric on the Atari 2600 Centipede dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Centipede"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(x) AS max_score, y AS metric WHERE { ?x ?y ?z. ?z ?y 'Centipede' }	False
What are the models that have been benchmarked on the MNIST dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MNIST"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icml/Ortiz-JimenezMF21> ?answer. ?y <https://dblp.org/rec/journals/tcnn/KhanMZ19> ?answer. ?z <https://dblp.org/rec/conf/icra/Seraji87> ?answer. ?a <https://dblp.org/rec/conf/medes/KalamarasGAM18> ?answer. ?b <https://dblp.org/rec/conf/cdc/Rueda-EscobedoM15> ?answer. ?c <https://dblp.org/rec/conf/ijcnn/PirimGBPE10> ?answer. ?d <https://dblp.org/rec/conf/cogsci/DeyneNCP21> ?answer. ?e <https://dblp.org/rec/conf/iasam/AddyGR11> ?answer. ?f <https://dblp.org/rec/journals/corr/abs-2109-07208> ?answer. ?g <https://dblp.org/rec/conf/iasam/AddyGR11> ?answer. ?h <https://dblp.org/rec/conf/icnn/SwetsW97> ?answer. ?i <https://dblp.org/rec/conf/iasam/AddyGR11> ?answer. ?j <https://dblp.org/rec/journals/ijbc/AllioC10> ?answer. ?k <https://dblp.org/rec/conf/iasam/AddyGR11> ?answer. ?l <https://dblp.org/rec/conf/icnn/SwetsW97> ?answer. ?m <https://dblp.org/rec/conf/iasam/AddyGR11> ?answer. ?n <https://dblp.org/rec/conf/icnn/SwetsW97> ?answer. ?o <https://dblp.org/rec/conf/iasam/AddyGR11> ?answer. ?p <https://dblp.org/rec/conf/icnn/SwetsW97> ?answer. ?q <https://dblp.org/rec/conf/iasam/AddyGR11> ?answer. ?r <https://dblp.org/rec/conf/icnn/SwetsW97> ?answer. ?s <https://dblp.org/rec/conf/iasam/AddyGR11> ?answer. ?t <https://dblp.org/rec/conf/icnn/SwetsW97> ?answer. ?u <https://dblp.org/rec/conf/iasam/AddyGR11> ?answer. ?v <https://dblp.org/rec/conf/icnn/SwetsW97> ?answer. ?w <https://dblp.org/rec/conf/iasam/AddyGR11> ?answer. ?x <https://dblp.org/rec/conf/icnn/SwetsW97> ?answer. ?y <https://dblp.org/rec/conf/iasam/AddyGR11> ?answer. ?z <https://dblp.org/rec/conf/icnn/SwetsW97> ?answer }	False
Where did the study with maximal geographic scale take place?	SELECT ?location, ?location_label WHERE { { SELECT (MAX( ?geo_scale) AS ?max_geo_scale) WHERE { orkgr:R149849 orkgp:compareContribution ?contrib. ?contrib orkgp:P41568 ?geo_scale. } } orkgr:R149849 orkgp:compareContribution ?contrib. ?contrib orkgp:P41568 ?geo_scale; orkgp:P37524 ?location. ?location rdfs:label ?location_label. FILTER( ?geo_scale = ?max_geo_scale) }	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/sigir/FengTCCLL20> ?answer }	False
Provide a list of research paper titles and IDs that have benchmarked models on the WLPC dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WLPC"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/sensors/UnnikrishnanRBP21> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'Sensors'. ?x <https://dblp.org/rdf/schema#title> ?secondanswer }	False
What are the titles and IDs of research papers that include a benchmark for the TempEval-3 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""TempEval-3"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/ton/QianL16>. ?x <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?y <https://dblp.org/rec/journals/ton/QianL16>. ?y <https://dblp.org/rdf/schema#authoredBy> ?secondanswer FILTER ( ?y!= ?x) }	False
Could you provide a list of models that have been tested on the SciERC benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SciERC"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2204-10176> ?answer. ?y <https://dblp.org/rec/journals/corr/abs-2204-10176> ?answer FILTER ( ?y!= ?x) }	False
Indicate the model that performed best in terms of F1 metric on the CoNLL 2012 benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CoNLL 2012"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1805-12011> ?answer. ?y <https://dblp.org/rec/journals/corr/abs-1805-12011> ?answer FILTER ( ?y!= ?x) }	False
What are the models that have been benchmarked on the WMT2014 English-German dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2014 English-German"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/tac/ShujaeeL97> ; ?answer <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rec/journals/titb/AungLTZ18> ; ?answer <https://dblp.org/rdf/schema#authoredBy> ?y }	False
What is the highest benchmark result achieved on the Yelp-14 dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Yelp-14"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x yelp:yearOfPublication '2014'. ?x yelp:numberOfPositiveReviews ?y. ?x yelp:numberOfNegativeReviews ?z. BIND(( ?y - ?z) AS ?answer) }	False
List the code links in papers that use the A3C FF (1 day) hs model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""A3C FF (1 day) hs"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcai/LiuHZA18> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Could you provide a list of models that have been tested on the RTE benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""RTE"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/RosenbergH09> ?answer. ?y <https://dblp.org/rec/conf/ijcnlp/DelicDD0B18> ?answer FILTER ( ?y!= ?x) }	False
What is the highest benchmark result achieved on the WOS-5736 dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WOS-5736"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x WOS-5736 ?y. ?x ?answer ?z }	False
Provide a list of research paper titles and IDs that have benchmarked models on the WebQuestions dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WebQuestions"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2005-00388> <https://dblp.org/rec/journals/ai/Clancey85> <https://dblp.org/rec/journals/ijon/ZhangX17> <https://dblp.org/rec/journals/ijon/LiuZ21> <https://dblp.org/rec/conf/smc/BristowB17> <https://dblp.org/rec/conf/iros/ZhaoXGMX10> <https://dblp.org/rec/journals/corr/abs-2004-09494> <https://dblp.org/rec/journals/tvt/XiaLLAYM15> }	False
List the metrics that are used to evaluate models on the ART/CoreSC benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ART/CoreSC"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iscas/ContiCFORTV03> ?answer }	False
What are the models that have been benchmarked on the Natural Questions (short) dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Natural Questions (short)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the WMT2014 French-English dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2014 French-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x wmt2014_french_to_english ?answer }	False
Which model has achieved the highest Test perplexity score on the WikiText-2 benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Test perplexity"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WikiText-2"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x wikitext2_test_perplexity ?answer }	False
Where can I find code references in papers that have used the All-attention network - 18 layers model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""All-attention network - 18 layers"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/0001C0USLZ20> ?answer }	False
"Does paper ""Disambiguating authors in citations on the web and authorship correlations"" employe Cosine similarity?"	"ASK WHERE { orkgr:R6187 orkgp:compareContribution ?cont. ?paper orkgp:P31 ?cont; rdfs:label ?paper_title. ?cont orkgp:P5002 orkgr:R6006. FILTER(REGEX(STR( ?paper_title), ""Disambiguating authors in citations on the web and authorship correlations"", ""i"")) }"	ASK { <https://sciq.org/rec/journals/sigsoft/CarverKSP05> <https://sciq.org/rdf/schema#authoredBy> ?x. <https://sciq.org/rec/journals/sigsoft/CarverKSP05> <https://sciq.org/rdf/schema#authoredBy> ?y. COUNT( ?x AS ?count). COUNT( ?y AS ?count). BIND( ?count = ?count) }	False
Can you list the models that have been evaluated on the STS Benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""STS Benchmark"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x y ?answer. ?x z ?y }	False
Indicate the model that performed best in terms of Score metric on the Atari 2600 Freeway benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Freeway"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iccS/AlYahyaR16>. ?x <https://dblp.org/rdf/schema#Score> ?answer }	False
What are the titles and IDs of research papers that include a benchmark for the DCASE dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""DCASE"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL16>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL17>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL18>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL19>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL20>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL21>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL22>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL23>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL24>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL25>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL26>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL27>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL28>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL29>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL30>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL31>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL32>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL33>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL34>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL35>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL36>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL37>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL38>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL39>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL40>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL41>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL42>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL43>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL44>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL45>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL46>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL47>. ?x <https://dblp.org/rec/conf/dcase/ElizaldeKSBVRL48	False
What evaluation metrics are commonly used when benchmarking models on the Yelp Fine-grained classification dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Yelp Fine-grained classification"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2204-03743> ?answer }	False
Which model has achieved the highest Score score on the Atari 2600 River Raid benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 River Raid"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x score:Score ?answer. ?x domain:RiverRaid } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
Provide a list of papers that have utilized the BERT + BiLSTM + CRF Decoding model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""BERT + BiLSTM + CRF Decoding"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/naacl/Beale11>. ?secondanswer <https://dblp.org/rec/conf/naacl/Beale11>. }	False
Indicate the model that performed best in terms of Pearson Correlation metric on the MedSTS benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Pearson Correlation"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MedSTS"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/AmarelDNSTW99> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What are the titles and IDs of research papers that include a benchmark for the WSC dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WSC"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/jgo/BrimbergSS15>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2203-09376>. ?firstanswer <https://dblp.org/rec/conf/ismis/FerilliIF20>. ?firstanswer <https://dblp.org/rec/conf/semweb/PenalozaT13>. ?firstanswer <https://dblp.org/rec/conf/iscas/ChenO10>. ?firstanswer <https://dblp.org/rec/conf/semweb/PenalozaT13>. ?firstanswer <https://dblp.org/rec/conf/iscas/ChenO10>. ?firstanswer <https://dblp.org/rec/conf/ismis/FerilliIF20>. ?firstanswer <https://dblp.org/rec/journals/jgo/BrimbergSS15>. ?firstanswer <https://dblp.org/rec/conf/ismis/FerilliIF20>. ?firstanswer <https://dblp.org/rec/conf/semweb/PenalozaT13>. ?firstanswer <https://dblp.org/rec/conf/iscas/ChenO10>. ?firstanswer <https://dblp.org/rec/conf/semweb/PenalozaT13>. ?firstanswer <https://dblp.org/rec/conf/iscas/ChenO10>. ?firstanswer <https://dblp.org/rec/journals/jgo/BrimbergSS15> }	False
List the code links in papers that use the linear-chain CRFs model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""linear-chain CRFs"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ibpria/AltimirLM03> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the code links in papers that use the DrQA model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""DrQA"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/DuT09> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Which model has achieved the highest Accuracy score on the SST-5 Fine-grained classification benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SST-5 Fine-grained classification"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX(accuracy) AS max_accuracy WHERE { ?x sst5_accuracy ?answer }	False
What evaluation metrics are commonly used when benchmarking models on the ARC-PDN dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ARC-PDN"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/eacl/Kruijff-KorbayovaRKE03> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Which QA benchmarks incorporating more than 10000 questions?	"SELECT ?papers, ?papers_labels WHERE { ?papers rdf:type orkgc:Paper; orkgp:P31 ?contrib; rdfs:label ?papers_labels. ?contrib orkgp:P41923 ?questions_number_str. BIND(REPLACE( ?questions_number_str, ""[+]"", """") AS ?questions_number_preprocessed) BIND(xsd:integer(REPLACE( ?questions_number_preprocessed, """","""", """")) AS ?questions_number) FILTER( ?questions_number > 10000) }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/KoniecznyLM17> ?answer. ?answer <https://dblp.org/rec/journals/ai/KliegrBFM18> ?answer }	False
What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Berzerk dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Berzerk"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iscas/SamadianHA03> ?answer }	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Stanford Cars dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Stanford Cars"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/tip/ChenSG16>. ?firstanswer <https://dblp.org/rec/journals/tbe/MatsuokaRAM01>. ?firstanswer <https://dblp.org/rec/conf/dasfaa/ChenGZ08>. ?firstanswer <https://dblp.org/rec/conf/icca/BoscainGP18>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEcit/Shih04>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2004-09494>. ?firstanswer <https://dblp.org/rec/conf/IEEEwisa/XuXJH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2004-09494>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEwisa/XuXJH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEwisa/XuXJH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEwisa/XuXJH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEwisa/XuXJH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEwisa/XuXJH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEwisa/XuXJH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEwisa/XuXJH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEwisa/XuXJH19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/medinfo/KuballaSMTH19>. ?firstanswer <https://dblp.org/rec	False
What are the titles and IDs of research papers that include a benchmark for the BUCC German-to-English dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BUCC German-to-English"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/bucc/Beale11>. ?x <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'BUCC'. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2011'. ?x <https://dblp.org/rdf/schema#title> ?secondanswer }	False
What are the metrics of evaluation over the Stanford Cars dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Stanford Cars"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2104-05843> <https://dblp.org/rdf/schema#metrics> ?answer. ?x <https://dblp.org/rdf/schema#dataset> 'Stanford Cars' }	False
What are the titles and IDs of research papers that include a benchmark for the ShARe/CLEF eHealth corpus dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ShARe/CLEF eHealth corpus"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/pid/23/102> <https://dblp.org/rdf/schema#authoredBy> ?secondanswer }	False
For what piezoresistive material the least response time was obtained?	SELECT ?piezoresistive_materials WHERE { orkgr:R138374 orkgp:compareContribution ?contrib. ?contrib orkgp:P41021 ?piezoresistive_materials. ?contrib orkgp:P41022 ?response_time. } ORDER BY ASC( ?response_time) LIMIT 1	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/journals/sensors/SuFLLL13> <https://dblp.org/rdf/schema#material> ?answer } GROUP BY ?answer } ORDER BY ASC( ?count) LIMIT 1	False
List the code links in papers that use the GPT-2 (small) model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""GPT-2 (small)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/LoweTSL18> <https://dblp.org/rec/journals/ai/Clancey85> ?answer }	False
List the metrics that are used to evaluate models on the Atari 2600 Fishing Derby benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Fishing Derby"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/KliegrBF21> ?answer. ?y <https://dblp.org/rec/journals/ai/KliegrBF21> 'Fishing Derby' }	False
What is the best performing model benchmarking the ImageNet dataset in terms of Number of params metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Number of params"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ImageNet"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/Alemohammad0BB21> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you list the models that have been evaluated on the Atari 2600 Battle Zone dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Battle Zone"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1805-00312>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the code links in papers that use the BiT-M model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""BiT-M"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icassp/JoneidiJ20> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the highest benchmark result achieved on the Atari 2600 Star Gunner dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Star Gunner"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x ?y ?answer. ?x <https://dblp.org/rec/conf/icip/GeestT14> }	False
Can you provide links to code used in papers that benchmark the NASCell model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""NASCell"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iccS/NASCenturión-ZuccalliBCKS14> ?answer }	False
Where can I find code references in papers that have used the TCN model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""TCN"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icassp/LuoSXT18> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the top benchmark result (metric and value) over the dataset BUCC French-to-English?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BUCC French-to-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2205-13720> ?answer }	False
What is the top benchmark result (metric and value) over the dataset SQuAD2.0?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SQuAD2.0"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/MurphyR10>. ?x ?answer }	False
What is the top benchmark result (metric and value) over the dataset BC2GM?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BC2GM"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2206-09265>. ?x ?answer }	False
List the metrics that are used to evaluate models on the Story Cloze Test benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Story Cloze Test"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/MurphyR10> ?answer. ?y <https://dblp.org/rec/journals/ai/MurphyR10> ?answer FILTER ( ?y!= ?x) }	False
Who has contributed to the largest number of articles about coronavirus?	"SELECT ?author_name WHERE { { SELECT (COUNT( ?paper_) as ?max_n_papers) WHERE { ?paper_ a orkgc:Paper; rdfs:label ?title_; orkgp:P27 ?author_. FILTER(REGEX(STR( ?title_), ""2019-nCoV"")) } GROUP BY ?author_ ORDER BY DESC( ?max_n_papers) LIMIT 1 } ?paper a orkgc:Paper; rdfs:label ?title; orkgp:P27 ?author. OPTIONAL { ?author rdfs:label ?author_label } BIND(IF(BOUND( ?author_label), ?author_label, ?author) as ?author_name) FILTER(REGEX(STR( ?title), ""2019-nCoV"")) } GROUP BY ?author ?type ?author_name ?max_n_papers HAVING(COUNT( ?paper) = ?max_n_papers)"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://sciq.org/rdf/schema#authoredBy> ?answer. ?x <https://sciq.org/rdf/schema#publishedOn> 'Coronavirus' } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
What are the models that have been benchmarked on the DuIE dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""DuIE"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://duie.du.ac.in/duie/record/record_0001> <https://du.isbd/du#benchmarkedOn> ?answer }	False
What coolant does ASTRID reactor use?	"SELECT ?coolant ?coolant_label WHERE { ?ASTRID_reactor ?rdfs_label ""ASTRID""^^xsd:string. ?contrib ?reactor_predicate ?ASTRID_reactor. ?contrib ?predicates ?coolant. ?predicates rdfs:label ?predicates_label. FILTER(REGEX( ?predicates_label, ""coolant"")) ?coolant rdfs:label ?coolant_label. }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/icpram/BezdushnyBSM15> <https://dblp.org/rdf/schema#usedBy> ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Berzerk dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Berzerk"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/iscas/SamadianHA03>. ?x <https://dblp.org/rec/journals/tcst/YangPZ17>. ?x <https://dblp.org/rec/conf/IEEEcit/Shih04>. ?x <https://dblp.org/rec/journals/tvt/XiaLLCGZ14>. ?x <https://dblp.org/rec/conf/sigada/Sward09a>. ?x <https://dblp.org/rec/conf/chi/LyngsLSBSIKS19>. ?x <https://dblp.org/rec/conf/IEEEscc/LuWZ14>. ?x <https://dblp.org/rec/conf/itsc/LeeKBC12>. ?x <https://dblp.org/rec/conf/icra/ParkPY09>. ?x <https://dblp.org/rec/journals/ijar/Schwartz93>. ?x <https://dblp.org/rec/conf/iecon/KumarP21>. ?x <https://dblp.org/rec/conf/cvpr/AzarbayejaniHP93>. ?x <https://dblp.org/rec/conf/iecon/LeePL19>. ?x <https://dblp.org/rec/journals/ijon/AdalBSFT98>. ?x <https://dblp.org/rec/conf/icicic/ZhangNZLL06>. ?x <https://dblp.org/rec/conf/hci/FischerKNS21>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZX17>. ?x <https://dblp.org/rec/conf/itsc/LeeKBC12>. ?x <https://dblp.org/rec/conf/sigsoft/VanHilstN96>. ?x <https://dblp.org/rec/conf/icira/PanZL08>. ?x <https://dblp.org/rec/journals/tvt/XiaLLCGZ14>. ?x <https://dblp.org/rec/journals/ijbc/AllioC10>. ?x <https://dblp.org/rec/journals/tcst/YangPZ17>. ?x <https://dblp.org/rec/conf/IEEEssd/RachidH15>. ?x <https://dblp.org/rec/conf/icira/ParkPY09>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZX17>. ?x <https://dblp.org/rec/conf/sigada/Sward09a>. ?x <https://dblp.org/rec/conf/icira/PanZL08>. ?x <https://dblp.org/rec/conf/chi/LyngsLSBSIKS19>. ?x <https://dblp.org/rec/conf/IEEEscc/LuWZ14>. ?x <https://dblp.org/rec/conf/itsc/LeeKBC12>. ?x <https://dblp.org/rec/conf/icra/ParkPY09>. ?x <https://dblp.org/rec/conf/iecon/KumarP21>. ?x <https://dblp.org/rec/conf/cvpr/AzarbayejaniHP93>. ?x <https://dblp.org/rec/conf/iecon/LeePL19>. ?x <https://dblp.org/rec/journals/ijon/AdalBSFT98>. ?x <https://dblp.org/rec/conf/icicic/ZhangNZLL06>. ?x <https://dblp.org/rec/conf/hci/FischerKNS21>. ?answer <https://dblp.org/rec/conf/iscas/SamadianHA03>. ?	False
Can you list the models that have been evaluated on the Atari 2600 Skiing dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Skiing"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x model: ?answer. ?x evaluatedOn 'Skiing' }	False
What are the most commonly used benchmark datasets for the Text Summarization research field?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Text Summarization"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/journals/ai/HovySP09> ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 5	False
What are the metrics of evaluation over the Atari 2600 Tutankham dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Tutankham"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x score: ?answer. ?x domain: 'Tutankham' }	False
What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Tutankham dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Tutankham"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x score:Score ?answer. ?x dataset:Atari 2600 Tutankham } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
Can you list the models that have been evaluated on the PROTEINS dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""PROTEINS"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x PROTEINS: ?y. ?x ?answer }	False
What is the name of the top performing model in terms of F1 score when benchmarked on the Natural Questions (long) dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Natural Questions (long)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/conf/naqts/RautSF20> ?answer. ?x <https://dblp.org/rec/conf/naqts/RautSF20> <https://dblp.org/rdf/schema#F1> ?count } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
What are the metrics of evaluation over the CommitmentBank dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CommitmentBank"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x COMMITMENTBANK:dataset 'CommitmentBank'. ?x ?answer }	False
Can you provide links to code used in papers that benchmark the BiT-M (ResNet) model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""BiT-M (ResNet)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icassp/HermosillaR99>. ?x < ?answer>. ?y <https://dblp.org/rec/conf/icassp/HermosillaR99>. ?y < ?answer> FILTER ( ?y!= ?x) }	False
What is the best performing model benchmarking the ACE 2004 dataset in terms of RE+ Micro F1 metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""RE+ Micro F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ACE 2004"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the top benchmark score and its metric on the Nottingham dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Nottingham"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer MAX( ?metric) AS ?metric WHERE { ?x Nottingham_score ?answer. ?x Nottingham_metric ?metric }	False
What evaluation metrics are commonly used when benchmarking models on the STEM-ECR v1.0 dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""STEM-ECR v1.0"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/igarss/DoubkovaH06> <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#publishedIn> 'IGARSS'. ?y <https://dblp.org/rdf/schema#title> ?answer }	False
Can you provide links to code used in papers that benchmark the Multi-Perspective Matching (single model) model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Multi-Perspective Matching (single model)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/KimL07>. ?x < ?answer> ?y }	False
What models are being evaluated on the GAD dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""GAD"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x GAD:answer ?answer }	False
What are the metrics of evaluation over the PubMed 20k RCT dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""PubMed 20k RCT"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2007-14050> ?answer }	False
List the metrics that are used to evaluate models on the Gibson PointGoal Navigation benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Gibson PointGoal Navigation"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/MoralesB07>. ?x < ?answer> ?y }	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the AAPD dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""AAPD"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/icml/ZarembaMJF16> <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?firstanswer <https://dblp.org/rdf/schema#publishedIn> 'ICML'. ?thirdanswer <https://dblp.org/rec/conf/icml/ZarembaMJF16> <https://dblp.org/rdf/schema#title> ?secondanswer. ?thirdanswer <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?thirdanswer <https://dblp.org/rdf/schema#publishedIn> 'ICML' }	False
Where can I find code references in papers that have used the AxCell model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""AxCell"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/codes/VahidL96>. ?x < ?answer> ?y }	False
Can you provide links to code used in papers that benchmark the AWD-LSTM model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""AWD-LSTM"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1802-01570>. ?x < ?answer> }	False
What are the titles and IDs of research papers that include a benchmark for the PubMedQA dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""PubMedQA"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2004-07917> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?y <https://dblp.org/rdf/schema#publishedIn> 'PubMedQA'. ?y <https://dblp.org/rdf/schema#title> ?secondanswer }	False
Name the datasets that have been used for benchmarking in the Image Classification research problem?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Image Classification"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/cvpr/SabokrouKFA18> <https://dblp.org/rdf/schema#dataset> ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the Gibson PointGoal Navigation dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Gibson PointGoal Navigation"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/iscas/LoiK13>. ?x <https://dblp.org/rec/journals/ior/Sayin00> }	False
Which model has achieved the highest Score score on the Cheetah, run (DMControl500k) benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Cheetah, run (DMControl500k)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x score: ?answer. ?x evaluatedOn: 'DMControl500k'. ?x modeledOn: 'Cheetah, run' }	False
What is the top benchmark score and its metric on the Stanford Dogs dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Stanford Dogs"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer MAX( ?metric) AS ?metric WHERE { ?x score ?answer ?metric. ?x dataset 'Stanford Dogs' }	False
Indicate the model that performed best in terms of Senseval 2 metric on the Supervised: benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Senseval 2"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Supervised:"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/ResnikP06> ?answer. ?y <https://dblp.org/rec/journals/ai/ResnikP06> ?answer FILTER ( ?y!= ?x) }	False
Indicate the model that performed best in terms of Test perplexity metric on the WikiText-103 benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Test perplexity"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WikiText-103"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2203-07912> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the highest benchmark result achieved on the WMT2016 English-Russian dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2016 English-Russian"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x WMT2016EnglishRussian ?answer }	False
What is the most common lead compound?	SELECT ?compound WHERE { orkgr:R75638 orkgp:compareContribution ?contrib. ?contrib orkgp:P35194 ?compound. } ORDER BY DESC(COUNT( ?compound)) LIMIT 1	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://sciq.org/rdf/schema#leadCompound> ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Enduro dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Enduro"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x score:Score ?answer. ?x game:Enduro } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
Provide a list of papers that have utilized the C51 noop model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""C51 noop"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/ChenZ21> <https://dblp.org/rec/journals/ijon/	False
Can you provide links to code used in papers that benchmark the FABIR model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""FABIR"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2002-07987>. ?x < ?answer> }	False
What is the emergency type of AMBER Alert?	SELECT DISTINCT ?emergency_type WHERE { orkgr:R153500 orkgp:P31 ?contrib. ?contrib orkgp:P43093 ?emergency_type. }	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91> ?answer }	False
List the metrics that are used to evaluate models on the CoQA benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CoQA"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/DuaH17> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of F1 metric on the OntoNotes benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""OntoNotes"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/ZhouZ10>. ?x <https://dblp.org/rec/journals/ai/McGraw76>. ?answer <https://dblp.org/rdf/schema#bestF1Model> ?y FILTER ( ?y!= ?answer) }	False
What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Defender dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Defender"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/ijcai/ShekharD89> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'IJCAI'. ?y <https://dblp.org/rec/conf/ijcai/ShekharD89> <https://dblp.org/rdf/schema#title> ?firstanswer. ?y <https://dblp.org/rdf/schema#yearOfPublication> ?secondanswer }	False
Where can I find code references in papers that have used the Pointer + Coverage + EntailmentGen + QuestionGen model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Pointer + Coverage + EntailmentGen + QuestionGen"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/MurakamiT15>. ?x < ?answer> ?answerValue }	False
Provide a list of papers that have utilized the Switch Transformer model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Switch Transformer"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/icassp/MaduenoP21>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2109-13501>. ?secondanswer <https://dblp.org/rec/journals/corr/abs-2109-13501> }	False
Can you list the models that have been evaluated on the CommonsenseQA dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CommonsenseQA"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x CommonsenseQA: ?y. ?x Model: ?answer }	False
What evaluation metrics are commonly used when benchmarking models on the Amazon-2 dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Amazon-2"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/eacl/TsvetkovMD14> <https://dblp.org/rdf/schema#authoredBy> ?x. <https://dblp.org/rec/conf/eacl/TsvetkovMD14> <https://dblp.org/rdf/schema#publishedIn> 'EACL'. ?y <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#publishedIn> 'EACL' FILTER ( ?y!= <https://dblp.org/rec/conf/eacl/TsvetkovMD14>) ?answer <https://dblp.org/rdf/schema#authoredBy> ?x. ?answer <https://dblp.org/rdf/schema#publishedIn> 'EACL' FILTER ( ?answer!= <https://dblp.org/rec/conf/eacl/TsvetkovMD14>) }	False
List the code links in papers that use the A3C-CTS model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""A3C-CTS"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcai/LiuHPO17> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the top benchmark score and its metric on the Hutter Prize dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Hutter Prize"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer MAX( ?metric) AS ?metric WHERE { ?x answer ?answer ?x metric ?metric. ?x train_on Hutter Prize }	False
Which model has achieved the highest F1 score on the CoNLL 2003 (English) benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CoNLL 2003 (English)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the name of the top performing model in terms of Params score when benchmarked on the VTAB-1k dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Params"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""VTAB-1k"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1911-12060> <https://sciq.org/rdf/schema#Params> ?y. ?z <https://dblp.org/rec/journals/corr/abs-1911-12060> <https://sciq.org/rdf/schema#VTAB-1k> ?answer. ?z <https://sciq.org/rdf/schema#Params> ?y FILTER ( ?z!= ?x) }	False
Can you list benchmarked problems in the area of Artificial Intelligence?	"SELECT DISTINCT ?problem ?problem_lbl WHERE { ?rf a orkgc:ResearchField; rdfs:label ?rf_label. FILTER (str( ?rf_label) = ""Artificial Intelligence"") ?paper orkgp:P30 ?rf; orkgp:P31 ?cont. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. ?problem rdfs:label ?problem_lbl. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/igarss/DoubkovaH06>. ?x <https://dblp.org/rec/conf/igarss/DoubkovaH06> ?answer }	False
What are the models that have been benchmarked on the FSNS - Test dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""FSNS - Test"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2008-00975> ?answer. ?y <https://dblp.org/rec/journals/corr/abs-2008-00975> ?answer FILTER ( ?y!= ?x) }	False
What is the best performing model benchmarking the WMT2014 German-English dataset in terms of BLEU metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""BLEU"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2014 German-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/wmt/BechlerKTZS14> ?answer. }	False
Can you provide links to code used in papers that benchmark the BiLSTM-Attention + ELMo model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""BiLSTM-Attention + ELMo"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/pid/23/10872> <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/23/10872>. ?x <https://dblp.org/rdf/schema#publishedIn> 'CoNLL-NLP Hyphen'. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2019'. ?x <https://dblp.org/rdf/schema#title> ?title. ?title <https://dblp.org/rdf/schema#contains> ?answer }	False
What is the highest benchmark result achieved on the STS Benchmark dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""STS Benchmark"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x stsbmwlp:benchmark 'STS'. ?x stsbmwlp:metric ?answer }	False
Provide a list of papers that have utilized the Shake-Shake (SAM) model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Shake-Shake (SAM)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/iclr/0001C0USLZ20>. ?secondanswer <https://dblp.org/rec/conf/iclr/0001C0USLZ20>. ?secondanswer <https://dblp.org/rec/conf/iclr/0001C0USLZ20> <https://dblp.org/rec/conf/iclr/0001C0USLZ20> }	False
What are the most commonly used benchmark datasets for the Joint Entity and Relation Extraction research field?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Joint Entity and Relation Extraction"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x ?y ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 10	False
What evaluation metrics are commonly used when benchmarking models on the MultiRC dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MultiRC"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/Miles90> <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/journals/ai/MilesL88>. ?y <https://dblp.org/rec/journals/ai/MilesL88> <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/journals/ai/Miles90>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer FILTER ( ?x!= ?y) }	False
Where can I find code references in papers that have used the SRU++ Base model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""SRU++ Base"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/sigir/BallesterosP05> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of Score metric on the Atari 2600 Asteroids benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Asteroids"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iccS/Greiner95>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the title and ID of research papers that contain a benchmark over the WMT2014 German-English dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2014 German-English"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2005-00351> ?firstanswer. ?x <https://dblp.org/rec/journals/corr/abs-2005-00351> ?secondanswer }	False
What are the models that have been benchmarked on the SearchQA dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SearchQA"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/LiuT17> <https://dblp.org/rdf/schema#authoredBy> ?answer. ?x <https://dblp.org/rec/conf/naacl/LiuT17> <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT' }	False
What are the metrics of evaluation over the OntoNotes dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""OntoNotes"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/KuoLC00>. ?x <https://dblp.org/rdf/schema#numberOfCreators> ?answer }	False
What are the metrics of evaluation over the Atari 2600 Defender dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Defender"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2007-07060> ?answer }	False
What is the highest benchmark result achieved on the WMT2014 English-German dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2014 English-German"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x WMT2014EnglishGerman ?answer }	False
What are the titles and IDs of research papers that include a benchmark for the PWC Leaderboards (restricted) dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""PWC Leaderboards (restricted)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/pwc/0001W0RL18> ?firstanswer. ?x <https://dblp.org/rec/conf/pwc/0002W0RL18> ?secondanswer }	False
List the metrics that are used to evaluate models on the enwik8 benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""enwik8"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/journals/corr/abs-1808-01673> <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#evaluatedOn> 'enwik8'. ?y <https://dblp.org/rdf/schema#metric> ?answer }	False
What evaluation metrics are commonly used when benchmarking models on the TempEval-3 dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""TempEval-3"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/MavropoulosLSVK17>. ?x < ?answer> }	False
What is the most common location in the studies?	SELECT ?locations WHERE { orkgr:R111045 orkgp:compareContribution ?cont. ?cont orkgp:P37537 ?locations. } ORDER BY DESC(COUNT( ?locations)) LIMIT 1	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x ?y ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
Provide a list of papers that have utilized the BCN+ELMo model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""BCN+ELMo"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/corr/abs-1909-08008> <https://dblp.org/rec/journals/corr/abs-1909-08008> <https://dblp.org/rec/journals/corr/abs-1909-08008> ?secondanswer }	False
Indicate the model that performed best in terms of Pre-Training Dataset metric on the HMDB51 benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Pre-Training Dataset"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""HMDB51"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icassp/MiechASLSZ20> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you list the models that have been evaluated on the Classical music, 5 seconds at 12 kHz dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Classical music, 5 seconds at 12 kHz"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/smc/HsiehCL18> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of BLEU score metric on the IWSLT2014 German-English benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""BLEU score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""IWSLT2014 German-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iwslt/BechlerMS13> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of F1 metric on the BC5CDR-disease benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BC5CDR-disease"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/bspc/BowlesLKE14>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Skiing dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Skiing"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iccS/GamperDBP13> ?answer }	False
List the title and ID of research papers that contain a benchmark over the Atari 2600 Frostbite dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Frostbite"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2109-07208> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?y <https://dblp.org/rdf/schema#title> ?firstanswer. ?y <https://dblp.org/rdf/schema#yearOfPublication> ?secondanswer }	False
Can you provide links to code used in papers that benchmark the COMET - Direct model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""COMET - Direct"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/ChurchGHH89>. ?x < ?answer> ?y }	False
Could you provide a list of models that have been tested on the BUCC Russian-to-English benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BUCC Russian-to-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/bucc/ChengTLZ19> ?answer }	False
What is the highest benchmark result achieved on the Atari 2600 Boxing dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Boxing"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x ?y ?answer. ?x <https://dblp.org/rec/conf/eacl/Kruijff-KorbayovaRKE03> }	False
Which model has achieved the highest F1 score score on the Penn Treebank benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1 score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Penn Treebank"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the IWSLT2015 German-English dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""IWSLT2015 German-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/iwslt/ChoukseyDS17> <https://dblp.org/rdf/schema#metric> ?y. ?x <https://dblp.org/rdf/schema#score> ?answer. ?iwslt2015GermanEnglish <https://dblp.org/rdf/schema#metric> ?y. ?iwslt2015GermanEnglish <https://dblp.org/rdf/schema#score> ?answer }	False
What are the metrics of evaluation over the Atari 2600 Frostbite dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Frostbite"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcai/Osman18>. ?x <https://dblp.org/rec/conf/ijcai/YangCR18>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLLLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://dblp.org/rec/conf/ijcai/ZhangCLZGZ21>. ?x <https://db	False
What is the top benchmark score and its metric on the MultiNLI dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MultiNLI"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer_max MIN( ?answer) AS ?answer_min WHERE { ?x answer: ?answer. ?x metric: 'MultiNLI' }	False
Can you list the models that have been evaluated on the ImageNet ReaL dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ImageNet ReaL"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1909-08501> ?answer. ?x <https://dblp.org/rec/journals/corr/abs-1909-08501> <https://dblp.org/rec/journals/corr/abs-2205-13720> ?y. ?y <https://dblp.org/rec/journals/corr/abs-2205-13720> 'ImageNet ReaL' }	False
Which model has achieved the highest Accuracy score on the Reuters En-De benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Reuters En-De"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX( ?answer) AS ?max WHERE { ?x Answers( ?y, ?answer, 'Reuters En-De' ) }	False
Can you provide the highest benchmark result, including the metric and score, for the Kinetics-600 dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Kinetics-600"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/embc/WangSLJ06> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the metrics that are used to evaluate models on the Yelp-5 benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Yelp-5"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://yelp-5.github.io> <https://dblp.org/rec/conf/naacl/LiCZY16> ?answer }	False
Provide a list of papers that have utilized the BART model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""BART"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/naacl/LanCJM19> <https://dblp.org/rec/conf/naacl/LaCJ18> <https://dblp.org/rec/conf/naacl/LaCJ17> <https://dblp.org/rec/conf/naacl/LaCJ16> <https://dblp.org/rec/conf/naacl/LaCJ15> <https://dblp.org/rec/conf/naacl/LaCJ14> <https://dblp.org/rec/conf/naacl/LaCJ13> <https://dblp.org/rec/conf/naacl/LaCJ12> <https://dblp.org/rec/conf/naacl/LaCJ11> <https://dblp.org/rec/conf/naacl/LaCJ10> <https://dblp.org/rec/conf/naacl/LaCJ09> <https://dblp.org/rec/conf/naacl/LaCJ08> <https://dblp.org/rec/conf/naacl/LaCJ07> <https://dblp.org/rec/conf/naacl/LaCJ06> <https://dblp.org/rec/conf/naacl/LaCJ05> <https://dblp.org/rec/conf/naacl/LaCJ04> <https://dblp.org/rec/conf/naacl/LaCJ03> <https://dblp.org/rec/conf/naacl/LaCJ02> <https://dblp.org/rec/conf/naacl/LaCJ01> <https://dblp.org/rec/conf/naacl/LaCJ00> <https://dblp.org/rec/conf/naacl/LaC99> <https://dblp.org/rec/conf/naacl/LaC98> <https://dblp.org/rec/conf/naacl/LaC97> <https://dblp.org/rec/conf/naacl/LaC96> <https://dblp.org/rec/conf/naacl/LaC95> <https://dblp.org/rec/conf/naacl/LaC94> <https://dblp.org/rec/conf/naacl/LaC93> <https://dblp.org/rec/conf/naacl/LaC92> <https://dblp.org/rec/conf/naacl/LaC91> <https://dblp.org/rec/conf/naacl/LaC90> <https://dblp.org/rec/conf/naacl/LaC89> <https://dblp.org/rec/conf/naacl/LaC88> <https://dblp.org/rec/conf/naacl/LaC87> <https://dblp.org/rec/conf/naacl/LaC86> <https://dblp.org/rec/conf/naacl/LaC85> <https://dblp.org/rec/conf/naacl/LaC84> <https://dblp.org/rec/conf/naacl/LaC83> <https://dblp.org/rec/conf/naacl/LaC82> <https://dblp.org/rec/conf/naacl/LaC81> <https://dblp.org/rec/conf/naacl/LaC80> <https://dblp.org/rec/conf/naacl/LaC79> <https://dblp.org/rec/conf/naacl/LaC78> <https://dblp.org/rec/conf/naacl/LaC77> <https://dblp.org/rec/conf/naacl/LaC76> <https://dblp.org/rec/conf/naacl/LaC75> <https://dblp.org/rec/conf/naacl/LaC74> <https://dblp.org/rec/conf/naacl/LaC73> <https://dblp.org/rec/conf/naacl/LaC72	False
What is the top benchmark score and its metric on the Natural Questions (short) dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Natural Questions (short)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer_max WHERE { ?x <https://dblp.org/rec/conf/naacl/WangMLS18> ?answer. ?x <https://dblp.org/rec/conf/naacl/WangMLS18> ?y FILTER( ?y!= ?answer) }	False
What evaluation metrics are commonly used when benchmarking models on the Sequential CIFAR-10 dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Sequential CIFAR-10"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x { ?x > 'https://dblp.org/rec/conf/iclr/0001C0USLZ20' } . ?x { ?answer ?x } }	False
What is the top benchmark score and its metric on the Automatically labeled Medline abstracts corpus dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Automatically labeled Medline abstracts corpus"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer_max SELECT DISTINCT ?metric WHERE { ?x ?answer ?answer_max. ?x ?metric ?answer }	False
Name the datasets that have been used for benchmarking in the citation classification research problem?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""citation classification"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icassp/MiaoYHLH22> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the code links in papers that use the H-NLI model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""H-NLI"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/ChenSZW21> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What are the titles and IDs of research papers that include a benchmark for the PubMed 20k RCT dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""PubMed 20k RCT"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/igarss/MertensBVW04>. ?x <https://dblp.org/rdf/schema#title> ?firstanswer. ?x <https://dblp.org/rdf/schema#authoredBy> ?secondanswer }	False
Indicate the model that performed best in terms of Macro Recall metric on the NLP-TDMS (Exp, arXiv only) benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Macro Recall"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2001-07827>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the name of the top performing model in terms of NLL score when benchmarked on the Nottingham dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""NLL"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Nottingham"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ibpria/NovovicovaM03>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Where can I find code references in papers that have used the DCN model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""DCN"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/air/Yang22>. ?x < ?answer> ?y }	False
What is the best performing model benchmarking the iNaturalist 2018 dataset in terms of Top-1 Accuracy metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Top-1 Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""iNaturalist 2018"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/cvpr/ZhengJ13>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the top benchmark score and its metric on the Atari 2600 Ice Hockey dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Ice Hockey"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer_max ?metric WHERE { ?x ?answer ?metric. ?x <https://dblp.org/rec/conf/ijcai/VaishG17> }	False
Provide a list of benchmarked datasets related to the Scientific Results Extraction research area?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Scientific Results Extraction"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/mta/HafidhOKAE14> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What are the titles and IDs of research papers that include a benchmark for the Walker, walk (DMControl500k) dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Walker, walk (DMControl500k)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/embc/YangYEHLWZL18>. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?secondanswer }	False
Provide a list of benchmarked datasets related to the Semantic Role Labeling research area?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Semantic Role Labeling"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/HovyPF99> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of research paper titles and IDs that have benchmarked models on the WikiText-2 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WikiText-2"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rec/journals/ton/HungK96>. ?x <https://dblp.org/rec/conf/icassp/ZhouPZ11> <https://dblp.org/rec/journals/ijon/SanthanamD19>. ?x <https://dblp.org/rec/journals/ijbc/YeSZ18> <https://dblp.org/rec/conf/IEEEcit/Shih04>. ?x <https://dblp.org/rec/conf/ijcai/DoyleS89> <https://dblp.org/rec/conf/igarss/MarpuGC10>. ?x <https://dblp.org/rec/journals/ijbc/YeZZ19> <https://dblp.org/rec/conf/icmlc/XuLLZ13>. ?x <https://dblp.org/rec/conf/IEEEicci/ZhouLX08> <https://dblp.org/rec/journals/ijbc/YeZZ19> }	False
What are the metrics of evaluation over the PWC Leaderboards (restricted) dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""PWC Leaderboards (restricted)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://sciqa.org/datasets/pwc_leaderboards_restricted> ?answer }	False
List the code links in papers that use the Duel noop model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Duel noop"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcai/Li15> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the datasets benchmarked under the Fine-Grained Image Classification research problem?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Fine-Grained Image Classification"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/sensors/VarelaPBD16>. ?x <https://dblp.org/rdf/schema#benchmarkedOn> ?answer }	False
What evaluation metrics are commonly used when benchmarking models on the DRI Corpus dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""DRI Corpus"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/brain/BahramiSKBKFHM17>. ?x ?answer }	False
List the metrics that are used to evaluate models on the Oxford-IIIT Pets benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Oxford-IIIT Pets"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1908-09690> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the name of the top performing model in terms of Unpermuted Accuracy score when benchmarked on the Sequential CIFAR-10 dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Unpermuted Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Sequential CIFAR-10"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x UnpermutedAccuracy 1 ?answer. ?x dataset 'Sequential CIFAR-10' } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the STL-10 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""STL-10"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/tcnn/KayargaddeM96>. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?firstanswer <https://dblp.org/rdf/schema#publishedIn> 'IEEE Trans. Comput. Neural Syst.'. ?x <https://dblp.org/rec/journals/tip/LiLLSP15>. ?x <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'IEEE Trans. Image Process.'. ?y <https://dblp.org/rec/journals/tnn/DuroR99>. ?y <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?y <https://dblp.org/rdf/schema#publishedIn> 'Neurocomputing'. ?z <https://dblp.org/rec/journals/siamma/KaiserTW05>. ?z <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?z <https://dblp.org/rdf/schema#publishedIn> 'SIAM J. Math. Anal.'. ?firstanswer <https://dblp.org/rec/journals/tcnn/KayargaddeM96>. ?firstanswer <https://dblp.org/rdf/schema#title> 'VLSI Architectures for Neural Networks: A Survey'. ?x <https://dblp.org/rec/journals/tip/LiLLSP15>. ?x <https://dblp.org/rdf/schema#title> 'A Lattice Boltzmann Method for Image Denoising'. ?y <https://dblp.org/rec/journals/tnn/DuroR99>. ?y <https://dblp.org/rdf/schema#title> 'Discrete-time backpropagation for training synaptic delay-based artificial neural networks'. ?z <https://dblp.org/rec/journals/siamma/KaiserTW05>. ?z <https://dblp.org/rdf/schema#title> 'A Generalized Energy Functional for Plane Couette Flow' }	False
Could you provide a list of models that have been tested on the SciCite benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SciCite"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2201-11114> ?answer. ?y <https://dblp.org/rec/journals/corr/abs-2201-11114> ?answer FILTER ( ?y!= ?x) }	False
Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Skiing dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Skiing"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/iclr/Alemohammad0BB21> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'ICLR'. ?y <https://dblp.org/rec/conf/iclr/Alemohammad0BB21> <https://dblp.org/rdf/schema#title> ?firstanswer. ?y <https://dblp.org/rec/conf/iclr/Alemohammad0BB21> <https://dblp.org/rdf/schema#id> ?secondanswer }	False
List the metrics that are used to evaluate models on the VTAB-1k benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""VTAB-1k"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/AnayaRF19> <https://dblp.org/rdf/schema#authoredBy> ?answer { ?x <https://dblp.org/rdf/schema#yearOfPublication> '2019' } { ?x <https://dblp.org/rdf/schema#yearOfPublication> '2020' } { ?x <https://dblp.org/rdf/schema#yearOfPublication> '2021' } }	False
What is the name of the top performing model in terms of Score score when benchmarked on the Cart Pole (OpenAI Gym) dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Cart Pole (OpenAI Gym)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/conf/eacl/Kruijff-KorbayovaRKE03> ?answer. ?y <https://dblp.org/rec/conf/eacl/Kruijff-KorbayovaRKE03> ?answer. ?z <https://dblp.org/rec/conf/eacl/Kruijff-KorbayovaRKE03> ?answer. ?x <https://dblp.org/rec/conf/eacl/Kruijff-KorbayovaRKE03> ?count. ?y <https://dblp.org/rec/conf/eacl/Kruijff-KorbayovaRKE03> ?count. ?z <https://dblp.org/rec/conf/eacl/Kruijff-KorbayovaRKE03> ?count } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
List the code links in papers that use the Rfa-Gate-arccos model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Rfa-Gate-arccos"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcai/LiuLR09> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of F1 metric on the ShARe/CLEF eHealth corpus benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ShARe/CLEF eHealth corpus"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/almob/MadhavanR10>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What are the metrics of evaluation over the BioASQ dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BioASQ"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/brain/BahramiSKBKFHM17>. ?x ?answer }	False
What is the best performing model benchmarking the Atari 2600 Centipede dataset in terms of Score metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Centipede"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icip/TangMACH04> ?answer. ?x <https://dblp.org/rec/conf/icip/TangMACH04> <https://dblp.org/rdf/schema#Score> ?y. ?z <https://dblp.org/rec/conf/icip/WangYCP06> ?answer. ?z <https://dblp.org/rec/conf/icip/WangYCP06> <https://dblp.org/rdf/schema#Score> ?y }	False
What are the most commonly used benchmark datasets for the Natural Language Inference research field?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Natural Language Inference"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/journals/ai/Beale08> ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 5	False
What models are being evaluated on the Classic dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Classic"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/journals/corr/abs-2203-05564> <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?y <https://dblp.org/rdf/schema#primaryAffiliation> ?answer }	False
Where can I find code references in papers that have used the DeiT-Ti model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""DeiT-Ti"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
For which country of study overall prevalence of epilepsy is the highest?	SELECT ?country, ?country_label WHERE { orkgr:R75729 orkgp:compareContribution ?contrib. ?contrib orkgp:P15512 ?country. ?contrib orkgp:P16013 ?overall_prevalence. ?country rdfs:label ?country_label. ?overall_prevalence rdfs:label ?overall_prevalence_value } ORDER BY DESC( ?overall_prevalence_value) LIMIT 1	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://csdtrc.org/rdf/schema#countryOfStudy> ?answer. ?x <https://csdtrc.org/rdf/schema#overallPrevalenceOfEpilepsy> ?count } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
Can you list the models that have been evaluated on the ShARe/CLEF eHealth corpus dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ShARe/CLEF eHealth corpus"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x y ?answer. ?x z 'ShARe/CLEF eHealth' }	False
Could you provide a list of models that have been tested on the HMDB51 benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""HMDB51"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icassp/MirchandaniFRHO00> ?answer. ?answer <https://dblp.org/rec/conf/icassp/MirchandaniFRHO00> ?x FILTER ( ?x!= ?answer) }	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Venture dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Venture"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91> <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?firstanswer <https://dblp.org/rdf/schema#publishedIn> 'IJCAI'. ?firstanswer <https://dblp.org/rdf/schema#title> ?thirdanswer }	False
List the metrics that are used to evaluate models on the Rotowire (Content Selection) benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Rotowire (Content Selection)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/pid/79/549> <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/79/549>. <https://dblp.org/pid/79/549> <https://dblp.org/rdf/schema#publishedIn> 'Rotowire (Content Selection)'. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/79/549>. ?x <https://dblp.org/rdf/schema#publishedIn> 'Rotowire (Content Selection)'. ?x <https://dblp.org/rdf/schema#metric> ?answer }	False
Where can I find code references in papers that have used the Tsetlin Machine model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Tsetlin Machine"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/cdc/StorandtB15> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the top benchmark score and its metric on the Atari 2600 Breakout dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Breakout"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(x) AS max_score, y AS metric WHERE { ?x ?y ?z. ?z = 'Breakout' }	False
What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Bowling dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Bowling"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/nnsvs/BellemareJ0P16>. ?x <https://dblp.org/rdf/schema#publishedIn> 'NN-SVS @ AAAI'. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the code links in papers that use the FQF model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""FQF"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icml/CalandrielloCLV20>. ?x <https://dblp.org/rec/journals/corr/abs-2006-07937>. ?x <https://dblp.org/rec/conf/colt/MendelsonP05>. ?x <https://dblp.org/rec/conf/nips/ApostolopoulouL19>. ?x <https://dblp.org/rec/journals/corr/abs-1806-10126>. ?x <https://dblp.org/rec/conf/soda/LiuL13>. ?x <https://dblp.org/rec/journals/corr/abs-2002-06504>. ?x <https://dblp.org/rec/conf/stoc/GoldreichI12>. ?x <https://dblp.org/rec/journals/siamma/KaiserTW05>. ?x <https://dblp.org/rec/conf/icml/CalandrielloCLV20> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of Sequence error metric on the FSNS - Test benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Sequence error"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""FSNS - Test"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1805-00312> ?answer. }	False
What is the top benchmark result (metric and value) over the dataset ARC (Challenge)?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ARC (Challenge)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2104-00460>. ?x ?answer }	False
What are the titles and IDs of research papers that include a benchmark for the SciREX dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SciREX"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/sensors/ChenWKS18> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'Sensors'. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2018'. ?x <https://dblp.org/rdf/schema#title> ?firstanswer. ?x <https://dblp.org/rdf/schema#id> ?secondanswer }	False
Can you list the metrics used to evaluate models on the TSE-NER dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""TSE-NER"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/tse/MavropoulosGPPS15> <https://dblp.org/rdf/schema#authoredBy> ?x. <https://dblp.org/rec/conf/tse/MavropoulosGPPS15> <https://dblp.org/rdf/schema#primaryAffiliation> ?answer }	False
Where can I find code references in papers that have used the Concept Mention Extraction model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Concept Mention Extraction"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/RosenbergH09> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the code links in papers that use the OTF spelling+lemma (single) model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""OTF spelling+lemma (single)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/bibe/RaygozaZ17> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of papers that have utilized the A3C LSTM hs model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""A3C LSTM hs"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/ijcai/LiuHZZ18> <https://dblp.org/rec/conf/ijcai/0006WCHM18> <https://dblp.org/rec/conf/ijcai/0007WCHM18> <https://dblp.org/rec/conf/ijcai/0008WCHM18> <https://dblp.org/rec/conf/ijcai/0009WCHM18> <https://dblp.org/rec/conf/ijcai/0010WCHM18> <https://dblp.org/rec/conf/ijcai/0011WCHM18> <https://dblp.org/rec/conf/ijcai/0012WCHM18> <https://dblp.org/rec/conf/ijcai/0013WCHM18> <https://dblp.org/rec/conf/ijcai/0014WCHM18> <https://dblp.org/rec/conf/ijcai/0015WCHM18> <https://dblp.org/rec/conf/ijcai/0016WCHM18> <https://dblp.org/rec/conf/ijcai/0017WCHM18> <https://dblp.org/rec/conf/ijcai/0018WCHM18> <https://dblp.org/rec/conf/ijcai/0019WCHM18> <https://dblp.org/rec/conf/ijcai/0020WCHM18> <https://dblp.org/rec/conf/ijcai/0021WCHM18> <https://dblp.org/rec/conf/ijcai/0022WCHM18> <https://dblp.org/rec/conf/ijcai/0023WCHM18> <https://dblp.org/rec/conf/ijcai/0024WCHM18> <https://dblp.org/rec/conf/ijcai/0025WCHM18> <https://dblp.org/rec/conf/ijcai/0026WCHM18> <https://dblp.org/rec/conf/ijcai/0027WCHM18> <https://dblp.org/rec/conf/ijcai/0028WCHM18> <https://dblp.org/rec/conf/ijcai/0029WCHM18> <https://dblp.org/rec/conf/ijcai/0030WCHM18> <https://dblp.org/rec/conf/ijcai/0031WCHM18> <https://dblp.org/rec/conf/ijcai/0032WCHM18> <https://dblp.org/rec/conf/ijcai/0033WCHM18> <https://dblp.org/rec/conf/ijcai/0034WCHM18> <https://dblp.org/rec/conf/ijcai/0035WCHM18> <https://dblp.org/rec/conf/ijcai/0036WCHM18> <https://dblp.org/rec/conf/ijcai/0037WCHM18> <https://dblp.org/rec/conf/ijcai/0038WCHM18> <https://dblp.org/rec/conf/ijcai/0039WCHM18> <https://dblp.org/rec/conf/ijcai/0040WCHM18> <https://dblp.org/rec/conf/ijcai/0041WCHM18> <https://dblp.org/rec/conf/ijcai/0042WCHM18> <https://dblp.org/rec/conf/ijcai/0043WCHM18> <https://dblp.org/rec/conf/ijcai/0044WCHM18> <https://dblp.org/rec/conf/ijcai/0045WCHM18> <https://dblp.org/rec/conf/ij	False
Which model has achieved the highest Percentage error score on the SVHN benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Percentage error"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SVHN"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x svhnPercentageError ?answer }	False
Where can I find code references in papers that have used the LayerNorm HM-LSTM model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""LayerNorm HM-LSTM"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1802-01570>. ?x < ?answer> ?answerValue }	False
List the datasets benchmarked under the SPARQL query optimization research problem?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""SPARQL query optimization"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/tcom/ParkLM18> <https://dblp.org/rdf/schema#benchmarkedBy> ?answer }	False
What is the highest benchmark result achieved on the Amazon-2 dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Amazon-2"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x ANSWER: ?answer. ?x TESTED_ON: 'Amazon-2' }	False
Can you provide links to code used in papers that benchmark the Temporal Convolutional Network model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Temporal Convolutional Network"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/pid/89/6864> <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/89/6864>. ?x <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?x <https://dblp.org/rdf/schema#yearOfPublication> ?y. ?x <https://dblp.org/rdf/schema#title> ?title. ?title <https://dblp.org/rdf/schema#contains> ?answer }	False
Provide a list of papers that have utilized the BiT-S (ResNet) model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""BiT-S (ResNet)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/cvpr/ZoranCHGMK20> <https://dblp.org/rec/conf/cvpr/SabokrouKFA18> <https://dblp.org/rec/conf/wcsp/ZhangSSD18> <https://dblp.org/rec/journals/corr/abs-1805-00333> <https://dblp.org/rec/journals/corr/abs-1807-02983> <https://dblp.org/rec/journals/corr/abs-1809-08506> <https://dblp.org/rec/journals/corr/abs-1810-11262> <https://dblp.org/rec/journals/corr/abs-1811-01547> <https://dblp.org/rec/journals/corr/abs-1812-04102> <https://dblp.org/rec/journals/corr/abs-1812-04192> <https://dblp.org/rec/journals/corr/abs-1812-07511> <https://dblp.org/rec/journals/corr/abs-1812-09053> <https://dblp.org/rec/journals/corr/abs-1812-10416> <https://dblp.org/rec/journals/corr/abs-1812-10553> <https://dblp.org/rec/journals/corr/abs-1812-10686> <https://dblp.org/rec/journals/corr/abs-1812-11378> <https://dblp.org/rec/journals/corr/abs-1812-12085> <https://dblp.org/rec/journals/corr/abs-1812-12381> <https://dblp.org/rec/journals/corr/abs-1812-12416> <https://dblp.org/rec/journals/corr/abs-1812-12678> <https://dblp.org/rec/journals/corr/abs-1812-12853> <https://dblp.org/rec/journals/corr/abs-1812-12984> <https://dblp.org/rec/journals/corr/abs-1812-13072> <https://dblp.org/rec/journals/corr/abs-1812-13230> <https://dblp.org/rec/journals/corr/abs-1812-13312> <https://dblp.org/rec/journals/corr/abs-1812-13468> <https://dblp.org/rec/journals/corr/abs-1812-13592> <https://dblp.org/rec/journals/corr/abs-1812-13657> <https://dblp.org/rec/journals/corr/abs-1812-13711> <https://dblp.org/rec/journals/corr/abs-1812-13824> <https://dblp.org/rec/journals/corr/abs-1812-13984> <https://dblp.org/rec/journals/corr/abs-1812-14126> <https://dblp.org/rec/journals/corr/abs-1812-14232> <https://dblp.org/rec/journals/corr/abs-1812-14357> <https://dblp.org/rec/journals/corr/abs-1812-14504> <https://dblp.org/rec/journals/corr/abs-1812-14634> <https://dblp.org/rec/journals/corr/abs-1812-14768> <https://dblp.org/rec/journals/corr/abs-1812-14864> <https://dblp.org/rec/journals/corr/abs-1812-14976> <https://dblp.org/rec/journals/corr/abs	False
What is the highest benchmark result achieved on the WNLI dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WNLI"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x WNLI ?y. ?x ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the AAPD dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""AAPD"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/pid/64/687> <https://dblp.org/rdf/schema#authoredBy> ?y. ?y <https://dblp.org/rdf/schema#authoredBy> ?z. ?z <https://dblp.org/rdf/schema#authoredBy> ?a. ?a <https://dblp.org/rdf/schema#authoredBy> ?b. ?b <https://dblp.org/rdf/schema#authoredBy> ?c. ?c <https://dblp.org/rdf/schema#authoredBy> ?d. ?d <https://dblp.org/rdf/schema#authoredBy> ?e. ?e <https://dblp.org/rdf/schema#authoredBy> ?f. ?f <https://dblp.org/rdf/schema#authoredBy> ?g. ?g <https://dblp.org/rdf/schema#authoredBy> ?h. ?h <https://dblp.org/rdf/schema#authoredBy> ?i. ?i <https://dblp.org/rdf/schema#authoredBy> ?j. ?j <https://dblp.org/rdf/schema#authoredBy> ?k. ?k <https://dblp.org/rdf/schema#authoredBy> ?l. ?l <https://dblp.org/rdf/schema#authoredBy> ?m. ?m <https://dblp.org/rdf/schema#authoredBy> ?n. ?n <https://dblp.org/rdf/schema#authoredBy> ?o. ?o <https://dblp.org/rdf/schema#authoredBy> ?p. ?p <https://dblp.org/rdf/schema#authoredBy> ?q. ?q <https://dblp.org/rdf/schema#authoredBy> ?r. ?r <https://dblp.org/rdf/schema#authoredBy> ?s. ?s <https://dblp.org/rdf/schema#authoredBy> ?t. ?t <https://dblp.org/rdf/schema#authoredBy> ?u. ?u <https://dblp.org/rdf/schema#authoredBy> ?v. ?v <https://dblp.org/rdf/schema#authoredBy> ?w. ?w <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#authoredBy> ?z. ?z <https://dblp.org/rdf/schema#authoredBy> ?a. ?a <https://dblp.org/rdf/schema#authoredBy> ?b. ?b <https://dblp.org/rdf/schema#authoredBy> ?c. ?c <https://dblp.org/rdf/schema#authoredBy> ?d. ?d <https://dblp.org/rdf/schema#authoredBy> ?e. ?e <https://dblp.org/rdf/schema#authoredBy> ?f. ?f <https://dblp.org/rdf/schema#authoredBy> ?g. ?g <https://dblp.org/rdf/schema#authoredBy> ?h. ?h <https://dblp.org/rdf/schema#authoredBy> ?i. ?i <https://dblp.org/rdf/schema#authoredBy> ?j. ?j <https://dblp.org/rdf/schema#authoredBy> ?k. ?k <https://dblp.org/rdf/schema#authoredBy> ?l. ?l <https://dblp.org/rdf/schema#authoredBy> ?m. ?m <https://dblp.org/rdf/schema#authoredBy	False
What models are being evaluated on the FTD dataset dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""FTD dataset"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/igarss/DoubkovaH06> <https://dblp.org/rdf/schema#numberOfCreators> ?x. ?y <https://dblp.org/rdf/schema#authoredBy> ?answer. ?y <https://dblp.org/rdf/schema#publishedIn> 'IGARSS' }	False
What is the best performing model benchmarking the CIFAR-10 Image Classification dataset in terms of Percentage error metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Percentage error"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CIFAR-10 Image Classification"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcai/LiuH82> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the highest benchmark result achieved on the Walker, walk (DMControl500k) dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Walker, walk (DMControl500k)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/iscas/Yli-KaakinenSY04> <https://dblp.org/rdf/schema#yearOfPublication> '2004'. ?x <https://dblp.org/rec/journals/corr/abs-2004-05913> <https://dblp.org/rdf/schema#yearOfPublication> '2004'. ?x <https://dblp.org/rec/conf/iccv/FanL18> <https://dblp.org/rdf/schema#yearOfPublication> '2004' }	False
What evaluation metrics are commonly used when benchmarking models on the SciGEN dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SciGEN"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/semweb/VerhaegRH21> ?answer }	False
List the code links in papers that use the POP3D model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""POP3D"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iccS/BrugiereBVA19>. ?x < ?answer>. ?y <https://dblp.org/rec/conf/iccS/BrugiereBVA19>. ?y < ?answer> FILTER ( ?y!= ?x) }	False
Indicate the model that performed best in terms of Score metric on the Atari 2600 Tennis benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Tennis"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcai/OsokinSVL15> <https://dblp.org/rdf/schema#Score> ?answer }	False
What evaluation metrics are commonly used when benchmarking models on the UCF101 (finetuned) dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""UCF101 (finetuned)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/cvpr/ZhuMT05> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of research paper titles and IDs that have benchmarked models on the MPQA dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MPQA"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/naacl/Lavrentovich18> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?y <https://dblp.org/rdf/schema#publishedIn> 'MPQA'. ?y <https://dblp.org/rdf/schema#yearOfPublication> ?secondanswer }	False
What is the highest benchmark result achieved on the BC5CDR-chemical dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BC5CDR-chemical"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x BC5CDR-chemical ?answer }	False
Which model has achieved the highest SUCCESS score on the Habitat 2020 Object Nav test-std benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""SUCCESS"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Habitat 2020 Object Nav test-std"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX(SUCCESS) AS max_success WHERE { ?x SUCCESS ?y. ?y ANSWER_TYPE 'Habitat 2020 Object Nav test-std' }	False
Can you provide the highest benchmark result, including the metric and score, for the Paper Field dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Paper Field"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/igarss/DoubkovaH06>. ?x <https://dblp.org/rdf/schema#metric> ?answer }	False
Indicate the model that performed best in terms of Accuracy metric on the MLDoc Zero-Shot English-to-German benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MLDoc Zero-Shot English-to-German"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/HasanBA21> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the highest benchmark result achieved on the Atari 2600 Double Dunk dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Double Dunk"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/icc/0002CWCZ21> ?answer. ?x <https://dblp.org/rec/conf/icc/0002CWCZ21> ?y. ?y <https://dblp.org/rec/conf/icc/0002CWCZ21> 'Atari 2600 Double Dunk' }	False
Can you provide links to code used in papers that benchmark the BiDAF + Self Attention + ELMo (ensemble) model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""BiDAF + Self Attention + ELMo (ensemble)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/KimL17> ?answer. ?x <https://dblp.org/rec/journals/ai/KimL17> ?answer }	False
What is the top benchmark score and its metric on the Cheetah, run (DMControl500k) dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Cheetah, run (DMControl500k)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer MAX( ?metric) AS ?metric WHERE { ?x score ?answer ?metric. ?x dataset 'DMControl500k' }	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the STS Benchmark dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""STS Benchmark"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/ai/KimL07>. ?firstanswer <https://dblp.org/rec/journals/ai/BenferhatBKN16>. ?firstanswer <https://dblp.org/rec/journals/ai/CalvertL99>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGM16>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGM17>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGM18>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM19>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM20>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM21>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM22>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM23>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM24>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM25>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM26>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM27>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM28>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM29>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM30>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM31>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM32>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM33>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM34>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM35>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM36>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM37>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM38>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM39>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM40>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM41>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM42>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM43>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM44>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM45>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM46>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM47>. ?firstanswer <https://dblp.org/rec/journals/ai/CabanasCGMM	False
What is the top benchmark score and its metric on the Atari 2600 Alien dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Alien"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer MAX( ?metric) AS ?metric WHERE { ?x score: ?answer metric: ?metric. ?x dataset: 'Alien' }	False
What is the highest benchmark result achieved on the Birdsnap dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Birdsnap"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2109-12543> ?answer }	False
What models are being evaluated on the Atari 2600 Chopper Command dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Chopper Command"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2107-09355>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of Accuracy metric on the Stanford Cars benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Stanford Cars"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1905-05176>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of Precision metric on the RotoWire (Relation Generation) benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Precision"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""RotoWire (Relation Generation)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/chiir/Al-HarbiS16> ?answer. ?y <https://dblp.org/rec/conf/chiir/Al-HarbiS16> ?answer FILTER ( ?y!= ?x) }	False
List the metrics that are used to evaluate models on the SQuAD1.1 benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SQuAD1.1"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/MurakamiT15> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of papers that have utilized the Large mLSTM model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Large mLSTM"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/corr/abs-2205-12506> <https://dblp.org/rec/journals/corr/abs-2205-12506> <https://dblp.org/rec/journals/corr/abs-2205-12506> }	False
What models are being evaluated on the ACL Anthology dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ACL Anthology"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/Hajek82>. ?x < ?answer> }	False
Which model has achieved the highest Score score on the Atari 2600 Yars Revenge benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Yars Revenge"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x score:YarsRevenge ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
What models are being evaluated on the NCBI-disease dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NCBI-disease"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/semweb/VerhaegRH21> ?answer. ?x <https://dblp.org/rec/conf/semweb/VerhaegRH21> <https://dblp.org/rdf/schema#dataset> 'NCBI-disease' }	False
Can you provide the highest benchmark result, including the metric and score, for the Softcite dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Softcite"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1910-11262>. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2019'. ?x <https://dblp.org/rdf/schema#authoredBy> ?y. ?y <https://dblp.org/rdf/schema#primaryAffiliation> 'University of Duisburg-Essen, Germany'. ?x <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?answer <https://dblp.org/rdf/schema#metric> ?x <https://dblp.org/rdf/schema#score> ?y }	False
What are the metrics of evaluation over the Fashion-MNIST dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Fashion-MNIST"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcnn/LiZAXGH20> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the best performing model benchmarking the X-Sum dataset in terms of ROUGE-2 metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""ROUGE-2"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""X-Sum"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/ChenSG20> <https://dblp.org/rdf/schema#authoredBy> ?answer. ?x <https://dblp.org/rec/conf/naacl/ChenSG20> <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT' }	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the RotoWire (Relation Generation) dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""RotoWire (Relation Generation)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/naacl/RautSASVK19> <https://dblp.org/rec/conf/naacl/attribution> ?secondanswer. ?firstanswer <https://dblp.org/rec/conf/naacl/RautSASVK19> <https://dblp.org/rec/conf/naacl/ID> ?thirdanswer }	False
Can you provide links to code used in papers that benchmark the Fine-Grained Gating model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Fine-Grained Gating"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2105-13543>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the best performing model benchmarking the Atari 2600 Montezuma's Revenge dataset in terms of Average Return (NoOp) metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Average Return (NoOp)"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Montezuma's Revenge"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/KliegrBF21>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of papers that have utilized the Prior noop model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Prior noop"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/corr/abs-1805-00312>. ?firstanswer <https://dblp.org/rec/journals/ai/Clancey85>. ?secondanswer <https://dblp.org/rec/journals/ai/Clancey85> }	False
What is the best performing model benchmarking the WMT2016 English-Russian dataset in terms of BLEU score metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""BLEU score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2016 English-Russian"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1809-00796>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the name of the top performing model in terms of Top-1 Error Rate score when benchmarked on the Oxford-IIIT Pets dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Top-1 Error Rate"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Oxford-IIIT Pets"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/cvpr/GoringRFD14>. ?x <https://dblp.org/rec/conf/cvpr/KyriazisA13>. ?x <https://dblp.org/rec/conf/wcsp/ZhongHD12>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp.org/rec/journals/iet-spr/HattayBN15>. ?x <https://dblp	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Reuters-21578 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Reuters-21578"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/igarss/WangLJLLSY15> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/icassp/ZhouV11> ?secondanswer | ?firstanswer <https://dblp.org/rec/journals/tnn/DuroR99> ?secondanswer | ?firstanswer <https://dblp.org/rec/journals/corr/abs-1806-01502> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/icra/ParkL03> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/journals/corr/abs-1806-01521> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iros/ZhaoXGMX10> ?secondanswer | ?firstanswer <https://dblp.org/rec/journals/tie/LiMZTL20> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/ifip3-6/GracaC15> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec/conf/iasam/AddyGR11> ?secondanswer | ?firstanswer <https://dblp.org/rec	False
What models are being evaluated on the Penn Treebank (Character Level) dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Penn Treebank (Character Level)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1809-00798> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of papers that have utilized the ANODE model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""ANODE"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/igarss/MertensBVW04>. ?firstanswer <https://dblp.org/rec/journals/robotica/Andrew86>. ?secondanswer <https://dblp.org/rec/conf/anzcc/KarbasizadehDSV20> }	False
Provide a list of papers that have utilized the DY-MobileNetV3-Small model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""DY-MobileNetV3-Small"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/embc/YangYEHLWZL21> <https://dblp.org/rec/conf/embc/YangYHHGL19> <https://dblp.org/rec/conf/embc/YangYHHGL17> <https://dblp.org/rec/conf/embc/YangYHHGL15> <https://dblp.org/rec/conf/embc/YangYHHGL13> <https://dblp.org/rec/conf/embc/YangYHHGL11> <https://dblp.org/rec/conf/embc/YangYHHGL09> <https://dblp.org/rec/conf/embc/YangYHHGL07> <https://dblp.org/rec/conf/embc/YangYHHGL05> <https://dblp.org/rec/conf/embc/YangYHHGL03> <https://dblp.org/rec/conf/embc/YangYHHGL01> <https://dblp.org/rec/conf/embc/YangYHHGL99> <https://dblp.org/rec/conf/embc/YeHLWZ20> <https://dblp.org/rec/conf/embc/YeHLWZ18> <https://dblp.org/rec/conf/embc/YeHLWZ16> <https://dblp.org/rec/conf/embc/YeHLWZ14> <https://dblp.org/rec/conf/embc/YeHLWZ12> <https://dblp.org/rec/conf/embc/YeHLWZ10> <https://dblp.org/rec/conf/embc/YeHLWZ08> <https://dblp.org/rec/conf/embc/YeHLWZ06> <https://dblp.org/rec/conf/embc/YeHLWZ04> <https://dblp.org/rec/conf/embc/YeHLWZ02> <https://dblp.org/rec/conf/embc/YeHLWZ00> <https://dblp.org/rec/conf/embc/YeHLWZ99> <https://dblp.org/rec/conf/embc/YeHLWZ97> <https://dblp.org/rec/conf/embc/YeHLWZ95> <https://dblp.org/rec/conf/embc/YeHLWZ93> <https://dblp.org/rec/conf/embc/YeHLWZ91> <https://dblp.org/rec/conf/embc/YeHLWZ89> <https://dblp.org/rec/conf/embc/YeHLWZ87> <https://dblp.org/rec/conf/embc/YeHLWZ85> <https://dblp.org/rec/conf/embc/YeHLWZ83> <https://dblp.org/rec/conf/embc/YeHLWZ81> <https://dblp.org/rec/conf/embc/YeHLWZ79> <https://dblp.org/rec/conf/embc/YeHLWZ77> <https://dblp.org/rec/conf/embc/YeHLWZ75> <https://dblp.org/rec/conf/embc/YeHLWZ73> <https://dblp.org/rec/conf/embc/YeHLWZ71> <https://dblp.org/rec/conf/embc/YeHLWZ69> <https://dblp.org/rec/conf/embc/YeHLWZ67> <https://dblp.org/rec/conf/embc/YeHLWZ65> <https://dblp.org/rec/conf/embc/YeHLWZ63> <https://dblp.org/rec/conf/embc/YeHLWZ61> <https://dblp.org/rec/conf/embc	False
What is the highest benchmark result achieved on the FSNS - Test dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""FSNS - Test"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2203-05140> ?answer }	False
Where can I find code references in papers that have used the MPAD-path model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""MPAD-path"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icra/AmoozgarLPA19> ?answer }	False
What are the models that have been benchmarked on the BoolQ dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BoolQ"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1805-06359>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the BUCC German-to-English dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BUCC German-to-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x buccGermanToEnglish ?answer }	False
Which model has achieved the highest Score score on the Ball in cup, catch (DMControl100k) benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Ball in cup, catch (DMControl100k)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x Score xsd:integer( ?answer). ?x Ball in cup, catch (DMControl100k) }	False
List the code links in papers that use the Multi-Perspective Matching (ensemble) model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Multi-Perspective Matching (ensemble)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1805-00312> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the best performing model benchmarking the ImageNet 64x64 dataset in terms of Bits per dim metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Bits per dim"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ImageNet 64x64"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icml/Ortiz-JimenezMF21>. ?x <https://dblp.org/rdf/schema#BitsPerDim> ?answer }	False
What is the top benchmark result (metric and value) over the dataset CommonsenseQA?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CommonsenseQA"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/LinL05>. ?x <https://dblp.org/rec/journals/ai/AlonL08>. ?x <https://dblp.org/rec/journals/ai/LukacK17>. ?x <https://dblp.org/rec/journals/ai/SmithL22>. ?x <https://dblp.org/rec/journals/ai/LukacK17> <https://dblp.org/rec/journals/ai/AlonL08> <https://dblp.org/rec/journals/ai/SmithL22> <https://dblp.org/rec/journals/ai/LinL05> }	False
Are children examined in the studies?	"ASK { orkgr:R44979 orkgp:compareContribution ?contrib. ?contrib orkgp:P23161 ?population. FILTER(REGEX( ?population, ""ildren"")) }"	ASK { ?x <https://dblp.org/rec/conf/igarss/OnrubiaGPPQAC15> <https://dblp.org/rdf/schema#authoredBy> ?y. ?y <https://dblp.org/rdf/schema#primaryAffiliation> 'University of Cantabria, Santander, Spain' }	False
What is the highest benchmark result achieved on the CoQA dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CoQA"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x answer ?answer. ?x metric ?y. ?x dataset 'CoQA' }	False
What is the top benchmark score and its metric on the ImageNet V2 dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ImageNet V2"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(x) AS max_x, y WHERE { ?x ?y. ?y <https://dblp.org/rec/conf/cvpr/ZhengJ13> }	False
Which model has achieved the highest Score score on the Reacher, easy (DMControl500k) benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Reacher, easy (DMControl500k)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX( ?answer) AS ?max WHERE { ?x Score ?answer. ?x > 'DMControl500k' }	False
List the metrics that are used to evaluate models on the Quasart-T benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Quasart-T"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1809-08506> <https://dblp.org/rdf/schema#authoredBy> ?y. ?y <https://dblp.org/rdf/schema#primaryAffiliation> ?answer }	False
Can you list the models that have been evaluated on the Multimodal PISA dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Multimodal PISA"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2109-12960> ?answer. ?x <https://dblp.org/rec/journals/ijcgt/KegeleersSLB19> ?answer }	False
Can you list the metrics used to evaluate models on the Barabasi-Albert dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Barabasi-Albert"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/igarss/ChandrasekarLA14> <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#publishedIn> 'IGARSS'. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2014'. ?y <https://dblp.org/rdf/schema#title> 'Vertical profile classification algorithm for GPM'. ?y <https://dblp.org/rdf/schema#numberOfCreators> '3'. ?y <https://dblp.org/rdf/schema#primaryAffiliation> ?answer }	False
Can you list the metrics used to evaluate models on the Atari 2600 Zaxxon dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Zaxxon"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://sciq.org/datasets/Atari2600Zaxxon> <https://sciq.org/rdf/schema#metrics> ?answer }	False
What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot English-to-Spanish?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MLDoc Zero-Shot English-to-Spanish"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/NieLW21> <https://dblp.org/rdf/schema#authoredBy> ?answer. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2021' }	False
Indicate the model that performed best in terms of BLEU score metric on the WMT2016 English-German benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""BLEU score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2016 English-German"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1911-03459>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of benchmarked datasets related to the Sentence Classification research area?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Sentence Classification"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/ChurchGHH89> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the metrics that are used to evaluate models on the RotoWire (Content Ordering) benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""RotoWire (Content Ordering)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://sciq.org/benchmarks/RotoWire> <https://sciq.org/rdf/schema#metrics> ?answer }	False
What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-Italian dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MLDoc Zero-Shot English-to-Italian"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://sciq.org/datasets/MLDoc_Zero-Shot_English-to-Italian> <https://sciq.org/rdf/schema#evaluationMetric> ?answer }	False
Provide a list of papers that have utilized the Tokenlearner model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Tokenlearner"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/igarss/Li000Z19>. ?firstanswer <https://dblp.org/rec/journals/tip/ChangFCCC06>. ?secondanswer <https://dblp.org/rec/conf/naacl/Lavrentovich18> }	False
What models are being evaluated on the MedSTS dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MedSTS"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/pid/22/10007> <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#evaluatedOn> <https://dblp.org/rec/conf/medsts/AbdelAalAH17> }	False
What is the best performing model benchmarking the CoNLL++ dataset in terms of F1 metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""CoNLL++"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x y ?answer. ?x z 'CoNLL++' }	False
Provide a list of research paper titles and IDs that have benchmarked models on the UCF101 (finetuned) dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""UCF101 (finetuned)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/ijcga/BajajR95> <https://dblp.org/rec/journals/ijon/PangLZ16> <https://dblp.org/rec/journals/ijon/TraviesoA14> <https://dblp.org/rec/conf/icra/Seraji87> <https://dblp.org/rec/conf/semweb/PenalozaT13> <https://dblp.org/rec/journals/ijbc/KuznetsovS19> <https://dblp.org/rec/conf/iciar/HeldWLPW12> <https://dblp.org/rec/journals/corr/abs-2001-08981> <https://dblp.org/rec/journals/corr/abs-1806-10160> <https://dblp.org/rec/conf/medinfo/KuballaSMTH19> <https://dblp.org/rec/conf/cdc/ChikmagalurT21> <https://dblp.org/rec/journals/tcasII/LiLCYYH20> <https://dblp.org/rec/journals/ijgi/WangK18> <https://dblp.org/rec/journals/corr/abs-1905-06452> <https://dblp.org/rec/conf/cec/LinHZLL10> <https://dblp.org/rec/conf/iciar/MoreiraSMC12> <https://dblp.org/rec/journals/tcasII/LiLCYYH20> <https://dblp.org/rec/conf/iciar/HeldWLPW12> <https://dblp.org/rec/conf/cdc/ChikmagalurT21> <https://dblp.org/rec/conf/medinfo/KuballaSMTH19> <https://dblp.org/rec/conf/cec/LinHZLL10> <https://dblp.org/rec/conf/iciar/MoreiraSMC12> <https://dblp.org/rec/journals/tcasII/LiLCYYH20> <https://dblp.org/rec/conf/iciar/HeldWLPW12> <https://dblp.org/rec/conf/cdc/ChikmagalurT21> <https://dblp.org/rec/conf/medinfo/KuballaSMTH19> <https://dblp.org/rec/conf/cec/LinHZLL10> <https://dblp.org/rec/conf/iciar/MoreiraSMC12> <https://dblp.org/rec/journals/tcasII/LiLCYYH20> <https://dblp.org/rec/conf/iciar/HeldWLPW12> <https://dblp.org/rec/conf/cdc/ChikmagalurT21> <https://dblp.org/rec/conf/medinfo/KuballaSMTH19> <https://dblp.org/rec/conf/cec/LinHZLL10> <https://dblp.org/rec/conf/iciar/MoreiraSMC12> <https://dblp.org/rec/journals/tcasII/LiLCYYH20> <https://dblp.org/rec/conf/iciar/HeldWLPW12> <https://dblp.org/rec/conf/cdc/ChikmagalurT21> <https://dblp.org/rec/conf/medinfo/KuballaSMTH19> <https://dblp.org/rec/conf/cec/LinHZLL10> <https://dblp.org/rec/conf/iciar/MoreiraSMC12> <https://dblp.org/rec/journals/tcasII/LiLCYYH20> <https://dblp.org/rec/conf/iciar/HeldWLPW12> <https://dblp.org/rec/conf/cdc/ChikmagalurT21> <https://dblp.org/rec/conf/medinfo/KuballaSMTH19	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SciCite dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SciCite"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer ?secondanswer ?thirdanswer. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91> }	False
Can you provide links to code used in papers that benchmark the ImageNet + iNat on WS-DAN model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""ImageNet + iNat on WS-DAN"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/wsc/ReillyLR19>. ?x <https://dblp.org/rec/conf/wsc/ReillyLR19> ?answer }	False
Can you list the metrics used to evaluate models on the BUCC Russian-to-English dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BUCC Russian-to-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x bucc:buccRussianToEnglish ?answer }	False
What is the best performing model benchmarking the AESLC dataset in terms of ROUGE-1 metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""ROUGE-1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""AESLC"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x AESLC:ROUGE-1 ?answer }	False
What is the top benchmark score and its metric on the ModelNet40 dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ModelNet40"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer_max, ?answer_metric WHERE { ?x <https://dblp.org/rec/conf/wscg/GonzatoP04> <https://dblp.org/rdf/schema#authoredBy> ?answer. ?x <https://dblp.org/rdf/schema#publishedIn> 'ModelNet'. ?answer <https://dblp.org/rdf/schema#primaryAffiliation> 'University of Padua, Italy' }	False
List the metrics that are used to evaluate models on the Penn Treebank benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Penn Treebank"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2002-07691> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Could you provide a list of models that have been tested on the Reuters-21578 benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Reuters-21578"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ijon/YanXLHZ21> ?answer. ?y <https://dblp.org/rec/journals/ijon/LiuZ21> ?answer FILTER ( ?y!= ?x). ?z <https://dblp.org/rec/journals/ijon/ZhangK22> ?answer FILTER ( ?z!= ?x. ?z!= ?y) }	False
What is the best performing model benchmarking the Atari 2600 Seaquest dataset in terms of Score metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Seaquest"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iccS/GuptaT15>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What are the metrics of evaluation over the seel.cse.lsu.edu/data/re17.zip  dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip "") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://seel.cse.lsu.edu/data/re17.zip> ?answer }	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the ObjectNet dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ObjectNet"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/cvpr/KononenkoSRS17> <https://dblp.org/rec/journals/corr/abs-2007-14050> <https://dblp.org/rec/conf/icip/ZillyMEK10> <https://dblp.org/rec/journals/corr/abs-1809-08506> <https://dblp.org/rec/conf/icra/MaturanaAS17> <https://dblp.org/rec/conf/iasam/AddyGR11> <https://dblp.org/rec/conf/cogsci/DeyneNCP21> <https://dblp.org/rec/conf/iccd/Fujita15> <https://dblp.org/rec/conf/chi/Jiang20> <https://dblp.org/rec/conf/iccsa/BaekKS09> <https://dblp.org/rec/journals/jifs/BuyukozkanHFG20> <https://dblp.org/rec/journals/ijbc/AllioC10> <https://dblp.org/rec/journals/corr/abs-2006-12720> <https://dblp.org/rec/journals/ijon/ChenX09> <https://dblp.org/rec/journals/corr/abs-2102-08771> <https://dblp.org/rec/conf/medinfo/KuballaSMTH19> <https://dblp.org/rec/conf/cogsci/DeyneNCP21> <https://dblp.org/rec/conf/iasam/AddyGR11> <https://dblp.org/rec/conf/cvpr/KononenkoSRS17> <https://dblp.org/rec/journals/corr/abs-2007-14050> <https://dblp.org/rec/conf/icip/ZillyMEK10> <https://dblp.org/rec/journals/corr/abs-1809-08506> <https://dblp.org/rec/conf/icra/MaturanaAS17> <https://dblp.org/rec/conf/iasam/AddyGR11> <https://dblp.org/rec/conf/cogsci/DeyneNCP21> <https://dblp.org/rec/conf/iccd/Fujita15> <https://dblp.org/rec/conf/chi/Jiang20> <https://dblp.org/rec/conf/iccsa/BaekKS09> <https://dblp.org/rec/journals/jifs/BuyukozkanHFG20> <https://dblp.org/rec/journals/ijbc/AllioC10> <https://dblp.org/rec/journals/corr/abs-2006-12720> <https://dblp.org/rec/journals/ijon/ChenX09> <https://dblp.org/rec/journals/corr/abs-2102-08771> <https://dblp.org/rec/conf/medinfo/KuballaSMTH19> }	False
List the metrics that are used to evaluate models on the Atari 2600 HERO benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 HERO"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/0001C0USLZ20> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What are the titles and IDs of research papers that include a benchmark for the Amazon-2 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Amazon-2"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/ai/Kass86>. ?firstanswer <https://dblp.org/rec/conf/igarss/MasekJRSCD18> }	False
Provide a list of papers that have utilized the Rainbow+SEER model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""Rainbow+SEER"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/sciqa/AllisonKD19>. ?firstanswer <https://dblp.org/rec/conf/sciqa/AllisonKD19> ?secondanswer }	False
What is the name of the top performing model in terms of Accuracy (High) score when benchmarked on the RACE dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy (High)"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""RACE"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2007-14050> <https://dblp.org/rdf/schema#AuthoredBy> ?answer }	False
Provide a list of research paper titles and IDs that have benchmarked models on the WMT2016 English-Romanian dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2016 English-Romanian"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/wmt/KoczkaP15> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'WMT'. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?x <https://dblp.org/rdf/schema#numberOfTranslations> ?secondanswer }	False
Can you list the metrics used to evaluate models on the MUTAG dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""MUTAG"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/icpram/GauraS15> <https://dblp.org/rdf/schema#publishedIn> 'ICPRAM (2)'. <https://dblp.org/rec/conf/icpram/GauraS15> <https://dblp.org/rdf/schema#yearOfPublication> '2015'. <https://dblp.org/rec/conf/icpram/GauraS15> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What evaluation metrics are commonly used when benchmarking models on the ESC-50 dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ESC-50"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x { ?x > 'ESC-50'. ?x > ?answer } }	False
Which model has achieved the highest F1 score on the SQuAD1.1 dev benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SQuAD1.1 dev"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/journals/ijon/HeK21> ?answer. ?y <https://dblp.org/rec/journals/ijon/HeK21> ?answer FILTER ( ?y!= ?x) }	False
What models are being evaluated on the TempEval-3 dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""TempEval-3"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ton/QianL16> ?answer. ?y <https://dblp.org/rec/journals/ton/QianL16> ?answer FILTER ( ?y!= ?x) }	False
What is the best performing model benchmarking the RotoWire (Content Ordering) dataset in terms of BLEU metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""BLEU"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""RotoWire (Content Ordering)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x RotoWire (Content Ordering) ?y. ?x ?answer ?z. ?z BLEU ?y }	False
What is the top benchmark score and its metric on the Atari 2600 Seaquest dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Seaquest"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer_max ?metric WHERE { ?x ?answer ?metric. ?x ?y 'Seaquest' }	False
Could you provide a list of models that have been tested on the GENIA - LAS benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""GENIA - LAS"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/braininf/ChenGWD20> ?answer. ?y <https://dblp.org/rec/journals/braininf/ChenGWD20> ?answer FILTER ( ?y!= ?x) }	False
Provide a list of research paper titles and IDs that have benchmarked models on the Yelp Binary classification dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Yelp Binary classification"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/ijcai/Li15> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'IJCAI'. ?y <https://dblp.org/rec/conf/ijcai/LiWZ18> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?y <https://dblp.org/rdf/schema#publishedIn> 'IJCAI'. ?firstanswer <https://dblp.org/rdf/schema#primaryAffiliation> 'University of Illinois at Chicago, USA'. ?firstanswer <https://dblp.org/rdf/schema#webpage> 'https://pages.uic.edu/~lixiao/'. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?firstanswer <https://dblp.org/rdf/schema#publishedIn> 'IJCAI'. ?firstanswer <https://dblp.org/rdf/schema#title> ?firstanswer. ?firstanswer <https://dblp.org/rdf/schema#yearOfPublication> ?firstanswer. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?firstanswer <https://dblp.org/rdf/schema#publishedIn> 'IJCAI'. ?firstanswer <https://dblp.org/rdf/schema#title> ?firstanswer. ?firstanswer <https://dblp.org/rdf/schema#yearOfPublication> ?firstanswer }	False
Indicate the model that performed best in terms of Accuracy metric on the Amazon benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Accuracy"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Amazon"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/jgo/PatrascuN15> <https://dblp.org/rec/journals/corr/abs-1806-10128> :answer }	False
What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Bank Heist dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Bank Heist"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/icc/SzeK12> ?firstanswer. ?x <https://dblp.org/rec/conf/icc/SzeK12> ?secondanswer }	False
What is the name of the top performing model in terms of A2 score when benchmarked on the ANLI test dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""A2"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ANLI test"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/Beale11> <https://dblp.org/rdf/schema#authoredBy> ?answer. ?y <https://dblp.org/rec/conf/naacl/Beale11> <https://dblp.org/rdf/schema#authoredBy> ?answer. ?x <https://dblp.org/rdf/schema#A2> ?z. ?y <https://dblp.org/rdf/schema#A2> ?w. FILTER ( ?w > ?z) }	False
Could you provide a list of models that have been tested on the QNLI benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""QNLI"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/RosenbergHPL06> <https://dblp.org/rdf/schema#numberOfCreators> ?y. ?x <https://dblp.org/rdf/schema#numberOfCreators> ?z. BIND(IF( ?y > ?z, ?x, ?answer) AS ?answer) }	False
What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Asterix dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Asterix"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/iclr/0001C0USLZ20> ?firstanswer. ?x <https://dblp.org/rec/conf/iclr/0001C0USLZ20> ?secondanswer }	False
Can you provide links to code used in papers that benchmark the MFEC model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""MFEC"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ijon/ChenYZ05>. ?x < ?answer> }	False
Can you provide links to code used in papers that benchmark the CAIT-XS-36 model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""CAIT-XS-36"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iscas/AshrafM05> ?answer. ?y <https://dblp.org/rec/conf/iscas/AshrafM05> ?answer FILTER ( ?y!= ?x) }	False
What models are being evaluated on the seel.cse.lsu.edu/data/re17.zip  dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip "") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icra/BicknellH98>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Indicate the model that performed best in terms of Score metric on the Atari 2600 Montezuma's Revenge benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Montezuma's Revenge"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1805-00312>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the best performing model benchmarking the ImageNet ReaL dataset in terms of Params metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Params"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ImageNet ReaL"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/siggraph/Chupa97d>. ?x <https://dblp.org/rdf/schema#params> ?answer }	False
Can you provide links to code used in papers that benchmark the ResNet-152 (SAM) model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""ResNet-152 (SAM)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icassp/RadosavC11>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the Pubmed dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Pubmed"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2204-10176> ?answer. ?x <https://dblp.org/rec/journals/corr/abs-2204-10176> ?y FILTER( ?y!= ?answer). ?y <https://dblp.org/rec/journals/corr/abs-2204-10176> ?answer }	False
Provide a list of research paper titles and IDs that have benchmarked models on the Walker, walk (DMControl100k) dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Walker, walk (DMControl100k)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/ijcai/LiuH22> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rec/conf/ijcai/LiuH22> <https://dblp.org/rdf/schema#publishedIn> 'IJCAI'. ?y <https://dblp.org/rec/conf/ijcai/LiuH22> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?y <https://dblp.org/rec/conf/ijcai/LiuH22> <https://dblp.org/rdf/schema#publishedIn> 'IJCAI'. ?x <https://dblp.org/rec/conf/ijcai/LiuH22> <https://dblp.org/rdf/schema#title> ?firstanswer. ?y <https://dblp.org/rec/conf/ijcai/LiuH22> <https://dblp.org/rdf/schema#title> ?firstanswer. ?x <https://dblp.org/rec/conf/ijcai/LiuH22> <https://dblp.org/rdf/schema#yearOfPublication> ?secondanswer. ?y <https://dblp.org/rec/conf/ijcai/LiuH22> <https://dblp.org/rdf/schema#yearOfPublication> ?secondanswer }	False
What is the highest benchmark result achieved on the REDDIT-B dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""REDDIT-B"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x subreddit 'REDDIT-B' ?x metric ?answer }	False
What models are being evaluated on the Softcite dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Softcite"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/igarss/HuberWHR07> ?answer. ?x <https://dblp.org/rec/conf/igarss/SoftCite> 'true' }	False
Could you provide a list of models that have been tested on the SST-2 Binary classification benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SST-2 Binary classification"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1805-07548> ?answer. ?y <https://dblp.org/rec/journals/corr/abs-1805-07548> ?answer FILTER ( ?y!= ?x) }	False
What is the top benchmark score and its metric on the Hendrycks Test dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Hendrycks Test"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer MAX( ?metric) AS ?metric WHERE { ?x hendrycks_test ?answer. ?x hendrycks_metric ?metric }	False
Can you provide links to code used in papers that benchmark the KD-LSTMreg model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""KD-LSTMreg"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What are the titles and IDs of research papers that include a benchmark for the NLP-TDMS dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NLP-TDMS"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/igarss/DoubkovaH06>. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?secondanswer }	False
Can you list the models that have been evaluated on the ClueWeb09-B dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ClueWeb09-B"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x model: ?answer. ?x eval: ClueWeb09-B }	False
Can you list the metrics used to evaluate models on the DocRED (Human-annotated) dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""DocRED (Human-annotated)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of papers that have utilized the CvT-21 (384 res) model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""CvT-21 (384 res)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec/conf/icassp/Gao0BB21> <https://dblp.org/rec/conf/icassp/Chen0BB21> <https://dblp.org/rec/conf/icassp/Roy0BB21> <https://dblp.org/rec	False
Can you provide links to code used in papers that benchmark the FG fine-grained gate model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""FG fine-grained gate"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/pid/38/11092> <https://dblp.org/rec/journals/corr/abs-2101-05600>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the highest benchmark result achieved on the NYT29 dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NYT29"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x NYT29:answer ?answer }	False
Can you list the metrics used to evaluate models on the QNLI dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""QNLI"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/naacl/WilliamsPDH20> <https://dblp.org/rdf/schema#numberOfCreators> ?x. <https://dblp.org/rec/conf/naacl/WilliamsPDH20> <https://dblp.org/rdf/schema#authoredBy> ?y. ?y <https://dblp.org/rdf/schema#primaryAffiliation> 'University of Glasgow, School of Mathematics and Statistics, UK' }	False
Which model has achieved the highest Entity F1 score on the SciERC benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Entity F1"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SciERC"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2006-11438> ?answer. ?x <https://dblp.org/rec/journals/corr/abs-2006-11438> <https://dblp.org/rdf/schema#authoredBy> ?y. ?z <https://dblp.org/rdf/schema#authoredBy> ?y. ?z <https://dblp.org/rdf/schema#authoredBy> ?answer FILTER ( ?z!= ?x) } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
What evaluation metrics are commonly used when benchmarking models on the SST-5 Fine-grained classification dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""SST-5 Fine-grained classification"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/Mullen89> <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/152/1248>. ?x <https://dblp.org/rdf/schema#yearOfPublication> '1989'. ?x <https://dblp.org/rdf/schema#publishedIn> 'AI'. ?y <https://dblp.org/rec/journals/ai/Muller03> <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/152/1248>. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2003'. ?y <https://dblp.org/rdf/schema#publishedIn> 'AI'. ?answer <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/152/1248> }	False
Can you provide the highest benchmark result, including the metric and score, for the Natural Questions (long) dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Natural Questions (long)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#yearOfPublication> '1989'. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/rec/conf/naacl/Ward89>. ?x <https://dblp.org/rdf/schema#auth	False
What is the top benchmark result (metric and value) over the dataset WMT2016 Czech-English?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2016 Czech-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/wmt/BechlerKTZ16> ?answer. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2016' }	False
Which sectors are modeled as energy sectors and how often?	SELECT ?label COUNT( ?label) WHERE { ?sector rdfs:label ?label; a ?class. ?class owl:equivalentClass <http://openenergy-platform.org/ontology/oeo/OEO_00000367>. [ orkgp:P37668 ?sector ]. }	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1806-10128> <https://dblp.org/rdf/schema#energySector> ?answer } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 10	False
Provide a list of research paper titles and IDs that have benchmarked models on the Kinetics-600 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Kinetics-600"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/cogsci/DolscheidGC13> <https://dblp.org/rec/journals/jbi/LewisSMBMOMJSBK22> <https://dblp.org/rec/conf/medinfo/KuballaSMTH19> <https://dblp.org/rec/conf/isspa/Al-AliAAOF21> <https://dblp.org/rec/conf/iccd/BalasubramanianS15> <https://dblp.org/rec/journals/corr/abs-2207-06180> <https://dblp.org/rec/conf/icicic/ZhangNZLL06> <https://dblp.org/rec/conf/iwcmc/PapageorgiouK14> <https://dblp.org/rec/conf/chi/TanZWY19> <https://dblp.org/rec/conf/semweb/PereiraCJ17> <https://dblp.org/rec/conf/apsipa/ZhouL19> <https://dblp.org/rec/journals/ijbc/KuznetsovS19> <https://dblp.org/rec/journals/ijautcomp/ChenJW22> <https://dblp.org/rec/conf/itsc/LeeP18> <https://dblp.org/rec/journals/tcom/Papazafeiropoulos18> <https://dblp.org/rec/conf/cira/AbellardKB05> <https://dblp.org/rec/conf/siggraph/KawaiM17> <https://dblp.org/rec/conf/icca/BoscainGP18> <https://dblp.org/rec/journals/corr/abs-1905-13221> <https://dblp.org/rec/conf/embc/ChenQJZ20> <https://dblp.org/rec/journals/ijbc/KuznetsovS19> <https://dblp.org/rec/conf/iwcmc/PapageorgiouK14> <https://dblp.org/rec/conf/chi/TanZWY19> <https://dblp.org/rec/conf/apsipa/ZhouL19> <https://dblp.org/rec/conf/semweb/PereiraCJ17> <https://dblp.org/rec/conf/itsc/LeeP18> <https://dblp.org/rec/journals/tcom/Papazafeiropoulos18> <https://dblp.org/rec/conf/cira/AbellardKB05> <https://dblp.org/rec/conf/siggraph/KawaiM17> <https://dblp.org/rec/conf/icca/BoscainGP18> <https://dblp.org/rec/conf/embc/ChenQJZ20> <https://dblp.org/rec/conf/chi/TanZWY19> <https://dblp.org/rec/conf/apsipa/ZhouL19> <https://dblp.org/rec/conf/semweb/PereiraCJ17> <https://dblp.org/rec/conf/itsc/LeeP18> <https://dblp.org/rec/journals/tcom/Papazafeiropoulos18> <https://dblp.org/rec/conf/cira/AbellardKB05> <https://dblp.org/rec/conf/siggraph/KawaiM17> <https://dblp.org/rec/conf/icca/BoscainGP18> <https://dblp.org/rec/conf/embc/ChenQJZ20> <https://dblp.org/rec/conf/chi/TanZWY19> <https://dblp.org/rec/conf/apsipa/ZhouL19> <https://dblp.org/rec/conf/semweb/PereiraCJ17> <https://dblp.org/rec/conf/itsc/LeeP18> <https://dblp.org/rec/journals/tcom/Pap	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Rotowire (Content Selection) dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Rotowire (Content Selection)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/amia/MarshallS00>. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?firstanswer <https://dblp.org/rdf/schema#publishedIn> 'AMIA'. ?firstanswer <https://dblp.org/rdf/schema#title> ?thirdanswer. ?firstanswer <https://dblp.org/rec/conf/amia/MarshallS00> <https://dblp.org/rec/conf/amia/MarshallS00> <https://dblp.org/rec/conf/amia/MarshallS00> }	False
What are the precision, recall, and f1 values of all compared studies that used the algorithm naive bayes in combination with the machine learning feature bag of words to classfy user feedback as feature request? 	"SELECT ?precision ?recall ?f1 WHERE { orkgr:R112387 orkgp:compareContribution ?contrib. ?contrib orkgp:P15006 ?algorithms. ?algorithms rdfs:label ?alg_names. FILTER(REGEX( ?alg_names, ""Naive bayes"")) ?algorithms orkgp:P36075 ?features. ?features rdfs:label ?fea_names. FILTER(REGEX( ?fea_names, ""Bag of words"")) ?features orkgp:P37029 ?categories. ?categories rdfs:label ?cat_names. FILTER(REGEX( ?cat_names, ""Feature request"")) ?categories orkgp:P3004 ?precision; orkgp:P5015 ?recall; orkgp:P18037 ?f1. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?x ?firstanswer ?firstanswer. ?y ?secondanswer ?secondanswer. ?z ?thirdanswer ?thirdanswer. ?x ?secondanswer ?y. ?y ?thirdanswer ?z }	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Dmlab-30 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Dmlab-30"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/iclr/Alemohammad0BB21> <https://dblp.org/rec/journals/sigplan/PopaBB03> <https://dblp.org/rec/journals/ieicet/TongpoonB13> <https://dblp.org/rec/conf/aiia/CeruttiB19> <https://dblp.org/rec/journals/ijcga/DehkordiB10> <https://dblp.org/rec/conf/icip/WongB03> <https://dblp.org/rec/journals/jat/BasorCH15> <https://dblp.org/rec/conf/IEEEcit/ShihB10> <https://dblp.org/rec/journals/tie/BraunB04> <https://dblp.org/rec/journals/tcst/BaiB18> <https://dblp.org/rec/conf/sigsoft/VanHilstB95> <https://dblp.org/rec/journals/tcom/BoseB03> <https://dblp.org/rec/journals/tie/BoselliB09> <https://dblp.org/rec/conf/icira/BuettnerB08> <https://dblp.org/rec/conf/iscas/BernacchiaB00> <https://dblp.org/rec/journals/ijon/BoichotB97> <https://dblp.org/rec/conf/IEEEants/BraulioB15> <https://dblp.org/rec/conf/iros/BhattacharjeeB14> <https://dblp.org/rec/conf/iccd/BhargavaB80> <https://dblp.org/rec/conf/icra/BhattacharjeeB18> <https://dblp.org/rec/conf/icse/BogdanovaBB13> <https://dblp.org/rec/conf/icassp/BhattacharjeeB20> <https://dblp.org/rec/journals/tcas/BoselliB14> <https://dblp.org/rec/journals/tcns/BraunB17> <https://dblp.org/rec/conf/IEEEants/BraulioB16> <https://dblp.org/rec/conf/accv/BhattacharyaB04> <https://dblp.org/rec/conf/iasam/BoselliB08> <https://dblp.org/rec/conf/iccd/BhargavaBB80> <https://dblp.org/rec/conf/cvpr/BhattacharyaB14> <https://dblp.org/rec/journals/tnn/BernhardBB19> <https://dblp.org/rec/conf/wcsp/BaoB15> <https://dblp.org/rec/conf/cec/BrankeB08> <https://dblp.org/rec/conf/iasam/BoselliB09> <https://dblp.org/rec/journals/ijbc/BogdanovaBB13> <https://dblp.org/rec/conf/isnn/BernhardBB19> <https://dblp.org/rec/conf/icra/BhattacharjeeBB19> <https://dblp.org/rec/conf/icccn/BraulioB18> <https://dblp.org/rec/conf/iasam/BoselliBB07> <https://dblp.org/rec/conf/iasam/BoselliBB08> <https://dblp.org/rec/conf/iasam/BoselliBB09> <https://dblp.org/rec/conf/iasam/BoselliBB11> <https://dblp.org/rec/conf/iccd/BhargavaBB80> <https://dblp.org/rec/conf/iccd/BhargavaBB80> <https://dblp.org/rec/conf/iccd/BhargavaBB80> <https://dblp.org/rec/conf/iccd/BhargavaBB	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WMT2016 German-English dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2016 German-English"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/wmt/KocchjanGLH15>. ?firstanswer <https://dblp.org/rdf/schema#authoredBy> ?secondanswer. ?firstanswer <https://dblp.org/rdf/schema#publishedIn> 'WMT'. ?firstanswer <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?firstanswer <https://dblp.org/rdf/schema#title> ?thirdanswer }	False
What is the highest benchmark result achieved on the Cartpole, swingup (DMControl500k) dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Cartpole, swingup (DMControl500k)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/iscas/Yli-KaakinenSY04> ?answer. ?y <https://dblp.org/rec/conf/iscas/Yli-KaakinenSY04> ?answer FILTER ( ?y!= ?x) }	False
What are the models that have been benchmarked on the Automatically labeled Medline abstracts corpus dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Automatically labeled Medline abstracts corpus"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/eacl/Kruijff-KorbayovaRKE03>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the code links in papers that use the LSTM (Bai et al., 2018) model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""LSTM (Bai et al., 2018)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1805-07548> <https://dblp.org/rdf/schema#authoredBy> ?y. ?y <https://dblp.org/rdf/schema#primaryAffiliation> 'Microsoft Research, Redmond, USA'. ?x <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2018'. ?x <https://dblp.org/rdf/schema#title> 'Exploring Sequence Supervision for Optimal Transport'. ?x <https://dblp.org/rdf/schema#authoredBy> ?y. ?y <https://dblp.org/rdf/schema#primaryAffiliation> 'Microsoft Research, Redmond, USA'. ?x <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2018'. ?x <https://dblp.org/rdf/schema#title> 'Exploring Sequence Supervision for Optimal Transport'. ?x <https://dblp.org/rdf/schema#authoredBy> ?y. ?y <https://dblp.org/rdf/schema#primaryAffiliation> 'Microsoft Research, Redmond, USA'. ?x <https://dblp.org/rdf/schema#publishedIn> 'CoRR'. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2018'. ?x <https://dblp.org/rdf/schema#title> 'Exploring Sequence Supervision for Optimal Transport' }	False
What is the top benchmark result (metric and value) over the dataset Oxford-IIIT Pets?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Oxford-IIIT Pets"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1908-09690>. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2019'. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you provide links to code used in papers that benchmark the XLNet-Large model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""XLNet-Large"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/ChenDUET19> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Where can I find code references in papers that have used the EfficientNetV2-L model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""EfficientNetV2-L"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2104-06214>. ?x < ?answer> }	False
Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WOS-46985 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WOS-46985"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer ?thirdanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/journals/corr/abs-1909-04652> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/ChenQGSXZ13> <https://dblp.org/rec/journals/ijon/RibeiroA18> <https://dblp.org/rec/conf/cogsci/PosidCBS18> <https://dblp.org/rec/conf/embc/Chen	False
What is the highest benchmark result achieved on the Supervised: dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Supervised:"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/iscas/KagarisT99> <https://dblp.org/rdf/schema#yield> ?answer }	False
What is the best performing model benchmarking the ANLI test dataset in terms of A3 metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""A3"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ANLI test"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/Kass86>. ?y <https://dblp.org/rec/journals/tcst/YangBZH11>. ?z <https://dblp.org/rec/conf/igarss/WeaverMD03>. ?answer <https://dblp.org/rec/journals/ai/Kass86>. ?answer <https://dblp.org/rec/journals/tcst/YangBZH11>. ?answer <https://dblp.org/rec/conf/igarss/WeaverMD03> }	False
What are the metrics of evaluation over the iNaturalist 2019 dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""iNaturalist 2019"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://sciq.org/datasets/inaturalist-2019> <https://sciq.org/rdf/schema#metrics> ?answer }	False
What are the models that have been benchmarked on the Atari 2600 Space Invaders dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Space Invaders"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/Alemohammad0BB21> ?answer. ?y <https://dblp.org/rec/journals/corr/abs-1804-05918> ?answer FILTER ( ?y!= ?x) }	False
Which model has achieved the highest BLEU score score on the WMT2014 English-German benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""BLEU score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2014 English-German"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x compute BLEU score on WMT2014 English-German benchmark dataset. ?x ?answer }	False
Provide a list of research paper titles and IDs that have benchmarked models on the Cart Pole (OpenAI Gym) dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Cart Pole (OpenAI Gym)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/iscas/YamamotoO21> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?y <https://dblp.org/rec/conf/iscas/YamamotoO21> <https://dblp.org/rdf/schema#publishedIn> 'ISCSA'. ?z <https://dblp.org/rec/conf/iscas/YamamotoO21> <https://dblp.org/rdf/schema#title> ?firstanswer. ?z <https://dblp.org/rec/conf/iscas/YamamotoO21> <https://dblp.org/rdf/schema#id> ?secondanswer }	False
Provide a list of papers that have utilized the A3C FF hs model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""A3C FF hs"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/corr/abs-1802-08494>. ?secondanswer <https://dblp.org/rec/journals/corr/abs-1802-08494>. }	False
Where can I find code references in papers that have used the BiDAF + Self Attention + ELMo model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""BiDAF + Self Attention + ELMo"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1805-00312>. ?x < ?answer> }	False
List the metrics that are used to evaluate models on the NCBI Disease benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NCBI Disease"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1911-03757> <https://dblp.org/rdf/schema#yearOfPublication> '2019'. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Where can I find code references in papers that have used the 6-layer QRNN model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""6-layer QRNN"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/Alemohammad0BB21> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What models are being evaluated on the WOS-11967 dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WOS-11967"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { WOS-11967 ?x ?answer }	False
List the title and ID of research papers that contain a benchmark over the NYT24 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NYT24"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/naacl/ChurchGHH89> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#yearOfPublication> ?secondanswer }	False
Name the datasets that have been used for benchmarking in the Robot Navigation research problem?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Robot Navigation"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/robotica/DeffuantFBA99> :answer. ?y <https://dblp.org/rec/journals/robotica/KimP03> :answer FILTER ( ?y!= ?x) }	False
Could you provide a list of models that have been tested on the seel.cse.lsu.edu/data/refsq17.zip benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""seel.cse.lsu.edu/data/refsq17.zip"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/asc/ItaniLF20> ?answer. ?y <https://dblp.org/rec/journals/asc/ItaniLF20> ?answer FILTER ( ?y!= ?x) }	False
Could you provide a list of models that have been tested on the IMDb-M benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""IMDb-M"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/LiCZY16>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Where can I find code references in papers that have used the PEGASUS model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""PEGASUS"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/igarss/DoubkovaH06> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Provide a list of benchmarked datasets related to the Audio Classification research area?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Audio Classification"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icassp/SenocakRKK22> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the Cart Pole (OpenAI Gym) dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Cart Pole (OpenAI Gym)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/iscas/Yli-KaakinenSY04>. ?x <https://dblp.org/rec/journals/ieicet/HasegawaHI10>. ?x <https://dblp.org/rec/conf/miccai/KaneEBRWMM09>. ?x <https://dblp.org/rec/conf/IEEEcit/Shih04>. ?x <https://dblp.org/rec/conf/smc/OliveiraLV11>. ?x <https://dblp.org/rec/conf/semweb/PenalozaT13>. ?x <https://dblp.org/rec/journals/iet-cdt/LeeLKL02>. ?x <https://dblp.org/rec/conf/icra/ZhangK04>. ?x <https://dblp.org/rec/conf/icira/AmoozgarFNP11>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?x <https://dblp.org/rec/conf/IEEEic	False
What are the titles and IDs of research papers that include a benchmark for the Reacher, easy (DMControl100k) dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Reacher, easy (DMControl100k)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/amia/MarshallS00> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'AMIA'. ?y <https://dblp.org/rec/conf/amia/MarshallS00> <https://dblp.org/rdf/schema#title> ?firstanswer. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2000' }	False
Which model has achieved the highest MACs score on the ImageNet benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""MACs"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ImageNet"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT MAX(xsd:integer( ?answer)) AS ?answer WHERE { ?x macs:score ?answer. ?x macs:dataset 'ImageNet' }	False
Can you provide the highest benchmark result, including the metric and score, for the ACE 2005 dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ACE 2005"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/HovyBEV08>. ?x <https://dblp.org/rec/journals/ai/HovyBEV08> ?answer }	False
List the metrics that are used to evaluate models on the DBpedia benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""DBpedia"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/sensors/ChenWKS18> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What is the top benchmark result (metric and value) over the dataset Atari 2600 Enduro?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Enduro"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iccS/HuberJGK19> ?answer. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2019' }	False
What are the metrics of evaluation over the Hutter Prize dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Hutter Prize"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/icmlc/ChenWZS13> <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#publishedIn> 'ICMLC'. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2013'. ?y <https://dblp.org/rdf/schema#title> ?answer }	False
Can you provide the highest benchmark result, including the metric and score, for the seel.cse.lsu.edu/data/re17.zip  dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip "") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x sd:dataset'seel.cse.lsu.edu/data/re17.zip'. ?x sd:metric ?answer }	False
What is the top benchmark score and its metric on the Atari 2600 Wizard of Wor dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Wizard of Wor"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX(x) AS max_score, y AS metric WHERE { ?x ?y ?z. ?z 'Wizard of Wor' }	False
List the code links in papers that use the 12-layer Transformer-XL model in any benchmark?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""12-layer Transformer-XL"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2002-07612> ?answer. ?x <https://dblp.org/rec/journals/corr/abs-2002-07612> <https://dblp.org/rdf/schema#authoredBy> ?y. ?answer <https://dblp.org/rdf/schema#authoredBy> ?y FILTER ( ?answer!= ?x) }	False
What is the best performing model benchmarking the Atari 2600 Up and Down dataset in terms of Score metric?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Up and Down"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/eacl/Kruijff-KorbayovaRKE03> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Could you provide a list of models that have been tested on the NLP-TDMS (Exp, arXiv only) benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/igarss/DoubkovaH06> ?answer. ?y <https://dblp.org/rec/conf/igarss/DoubkovaH06> ?answer FILTER ( ?y!= ?x) }	False
What are the models that have been benchmarked on the  Jacquard dataset dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = "" Jacquard dataset"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://sciqa.org/datasets/55> <https://sciqa.org/rdf-schema#benchmarkedOn> ?answer }	False
What are the metrics of evaluation over the ObjectNet dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ObjectNet"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-1908-09690>. ?x ?answer }	False
Provide a list of research paper titles and IDs that have benchmarked models on the enwik8 dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""enwik8"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rec/conf/naacl/LiCZY16> <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https://dblp.org/rdf/schema#yearOfPublication> '2016'. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer FILTER ( ?y!= ?x). ?y <https://dblp.org/rdf/schema#publishedIn> 'NAACL-HLT'. ?y <https	False
Indicate the model that performed best in terms of PARAMS metric on the FGVC Aircraft benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""PARAMS"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""FGVC Aircraft"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/fgvc/WardL14> ; ?answer <https://dblp.org/rdf/schema#PARAMS> }	False
List the metrics that are used to evaluate models on the Atari 2600 Battle Zone benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Battle Zone"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/igarss/ChandrasekarLA14> ?answer. ?y <https://dblp.org/rec/conf/igarss/ChandrasekarLA14> ?answer FILTER ( ?y!= ?x) }	False
What are the models that have been benchmarked on the Atari 2600 Road Runner dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Road Runner"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/eacl/PinchakL06> ; ?answer <https://dblp.org/rdf/schema#authoredBy> ?x }	False
Can you list the models that have been evaluated on the Atari 2600 Boxing dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Boxing"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iccS/AlYahyaR16> ?answer. ?answer <https://dblp.org/rdf/schema#authoredBy> ?y. ?y <https://dblp.org/rdf/schema#primaryAffiliation> 'King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia' }	False
What evaluation metrics are commonly used when benchmarking models on the WMT2014 French-English dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""WMT2014 French-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/corr/abs-2005-00353> ?answer. ?y <https://dblp.org/rec/journals/corr/abs-2005-00353> ?answer FILTER ( ?y!= ?x) }	False
Can you list the models that have been evaluated on the BUCC French-to-English dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BUCC French-to-English"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/mta/KaddachiAABEMF20> ?answer }	False
Can you provide links to code used in papers that benchmark the BiDAF + Self Attention + ELMo (single model) model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""BiDAF + Self Attention + ELMo (single model)"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/pid/50/5016> <https://dblp.org/rec/journals/ai/Hendrickson82>. ?y <https://dblp.org/rec/journals/ai/SmithL98> <https://dblp.org/rec/journals/ai/SmithL98>. ?y <https://dblp.org/rec/journals/ai/SmithL98> <https://dblp.org/rec/journals/ai/Hendrickson82>. ?answer <https://dblp.org/rec/journals/ai/Hendrickson82>. ?answer <https://dblp.org/rec/journals/ai/SmithL98> }	False
What models are being evaluated on the AESLC dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""AESLC"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/journals/corr/abs-1910-11262> <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#authoredBy> ?x. ?y <https://dblp.org/rdf/schema#evaluatedOn> 'AESLC' }	False
What are the titles and IDs of research papers that include a benchmark for the HoC dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""HoC"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?x <https://dblp.org/rec/journals/ibmrd/Lew83>. ?x <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?x <https://dblp.org/rdf/schema#publishedIn> 'IBM J. Res. Dev.'. ?y <https://dblp.org/rec/journals/ibmrd/Lew84>. ?y <https://dblp.org/rdf/schema#authoredBy> ?firstanswer. ?y <https://dblp.org/rdf/schema#publishedIn> 'IBM J. Res. Dev.' }	False
Where can I find code references in papers that have used the PAR Transformer Large model for benchmarking purposes?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""PAR Transformer Large"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/icassp/KimY21> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
Can you provide links to code used in papers that benchmark the BERTwwm + SQuAD 2 model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""BERTwwm + SQuAD 2"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/Moosavi15> <https://dblp.org/rdf/schema#authoredBy> ?answer. ?x <https://dblp.org/rec/journals/ai/Moosavi15> <https://dblp.org/rdf/schema#publishedIn> 'Artif. Intell.' }	False
Provide a list of papers that have utilized the CL-Titles-Parser model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""CL-Titles-Parser"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/naacl/LiCZY16>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2004-09789>. ?firstanswer <https://dblp.org/rec/conf/coling GeeMBHGG17>. ?firstanswer <https://dblp.org/rec/conf/naacl/MurakamiT15>. ?firstanswer <https://dblp.org/rec/journals/tip/ChangFCCC06>. ?firstanswer <https://dblp.org/rec/conf/icassp/ZhouV11>. ?firstanswer <https://dblp.org/rec/journals/tcs/ChandrasekaranRAK04>. ?firstanswer <https://dblp.org/rec/conf/medinfo/AndersonBBE01>. ?firstanswer <https://dblp.org/rec/conf/icse/KlotinsUCGPTP18>. ?firstanswer <https://dblp.org/rec/conf/icassp/ElkhalilK0PK21>. ?firstanswer <https://dblp.org/rec/journals/corr/abs-2004-09789>. ?firstanswer <https://dblp.org/rec/journals/ijbc/AllioC10>. ?firstanswer <https://dblp.org/rec/conf/icip/WongL00>. ?firstanswer <https://dblp.org/rec/conf/iui/StumptnerT08>. ?firstanswer <https://dblp.org/rec/conf/igarss/MarpuGC10>. ?firstanswer <https://dblp.org/rec/conf/medinfo/AndersonBBE01>. ?firstanswer <https://dblp.org/rec/conf/igarss/MarpuGC10>. ?firstanswer <https://dblp.org/rec/conf/icse/KlotinsUCGPTP18>. ?firstanswer <https://dblp.org/rec/journals/ijbc/AllioC10>. ?firstanswer <https://dblp.org/rec/conf/icip/WongL00>. ?firstanswer <https://dblp.org/rec/conf/iui/StumptnerT08>. ?firstanswer <https://dblp.org/rec/conf/igarss/MarpuGC10>. ?firstanswer <https://dblp.org/rec/conf/medinfo/AndersonBBE01>. ?firstanswer <https://dblp.org/rec/conf/igarss/MarpuGC10>. ?firstanswer <https://dblp.org/rec/conf/icse/KlotinsUCGPTP18>. ?firstanswer <https://dblp.org/rec/journals/ijbc/AllioC10>. ?firstanswer <https://dblp.org/rec/conf/icip/WongL00>. ?firstanswer <https://dblp.org/rec/conf/iui/StumptnerT08>. ?firstanswer <https://dblp.org/rec/conf/igarss/MarpuGC10>. ?firstanswer <https://dblp.org/rec/conf/medinfo/AndersonBBE01>. ?firstanswer <https://dblp.org/rec/conf/igarss/MarpuGC10>. ?firstanswer <https://dblp.org/rec/conf/icse/KlotinsUCGPTP18>. ?firstanswer <https://dblp.org/rec/journals/ijbc/AllioC10>. ?firstanswer <https://dblp.org/rec/conf/icip/WongL00>. ?firstanswer <https://dblp.org/rec/conf/iui/StumptnerT08>. ?firstanswer <https://dblp.org/rec/conf/igarss/MarpuGC10>. ?firstanswer <https://dblp.org/rec/conf/medinfo/AndersonBBE01	False
Could you provide a list of models that have been tested on the Habitat 2020 Object Nav test-std benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Habitat 2020 Object Nav test-std"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/egh/KreegerK98>. ?x <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What models are being evaluated on the Atari 2600 Name This Game dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Name This Game"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://sciqa.org/datasets/Atari2600NameThisGame> <https://sciqa.org/rdf/schema#evaluatedBy> ?answer }	False
What is the highest benchmark result achieved on the Atari 2600 Freeway dataset, including the metric and its value?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Freeway"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/conf/ijcai/LiuLR09> ?answer. ?x <https://dblp.org/rec/conf/ijcai/LiuLR09> ?y. ?y 'Tiebreak' }	False
Could you provide a list of models that have been tested on the Atari 2600 River Raid benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 River Raid"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iccS/GeorgeB19> ?answer. ?y <https://dblp.org/rec/conf/iccS/GeorgeB19> ?answer FILTER ( ?y!= ?x) }	False
Provide a list of papers that have utilized the AlexNet, MultiGrasp model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""AlexNet, MultiGrasp"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/conf/cvpr/GdalyahuSW00>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW94>. ?firstanswer <https://dblp.org/rec/conf/ijcai/MaZL15>. ?firstanswer <https://dblp.org/rec/conf/ijcai/Zhang0SJ22>. ?firstanswer <https://dblp.org/rec/conf/ijcai/LiHL14>. ?firstanswer <https://dblp.org/rec/conf/ijcai/Zhang0SJ22>. ?firstanswer <https://dblp.org/rec/conf/ijcai/LiHL14>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW94>. ?firstanswer <https://dblp.org/rec/conf/ijcai/MaZL15>. ?firstanswer <https://dblp.org/rec/conf/ijcai/Zhang0SJ22>. ?firstanswer <https://dblp.org/rec/conf/ijcai/LiHL14>. ?firstanswer <https://dblp.org/rec/conf/ijcai/Zhang0SJ22>. ?firstanswer <https://dblp.org/rec/conf/ijcai/LiHL14>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW94>. ?firstanswer <https://dblp.org/rec/conf/ijcai/MaZL15>. ?firstanswer <https://dblp.org/rec/conf/ijcai/Zhang0SJ22>. ?firstanswer <https://dblp.org/rec/conf/ijcai/LiHL14>. ?firstanswer <https://dblp.org/rec/conf/ijcai/Zhang0SJ22>. ?firstanswer <https://dblp.org/rec/conf/ijcai/LiHL14>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW94>. ?firstanswer <https://dblp.org/rec/conf/ijcai/MaZL15>. ?firstanswer <https://dblp.org/rec/conf/ijcai/Zhang0SJ22>. ?firstanswer <https://dblp.org/rec/conf/ijcai/LiHL14>. ?firstanswer <https://dblp.org/rec/conf/ijcai/Zhang0SJ22>. ?firstanswer <https://dblp.org/rec/conf/ijcai/LiHL14>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW94>. ?firstanswer <https://dblp.org/rec/conf/ijcai/MaZL15>. ?firstanswer <https://dblp.org/rec/conf/ijcai/Zhang0SJ22>. ?firstanswer <https://dblp.org/rec/conf/ijcai/LiHL14>. ?firstanswer <https://dblp.org/rec/conf/ijcai/Zhang0SJ22>. ?firstanswer <https://dblp.org/rec/conf/ijcai/LiHL14>. ?firstanswer <https://dblp.org/rec/conf/ijcai/AmarelDNSTW91>.	False
Can you list the models that have been evaluated on the Atari 2600 Ms. Pacman dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Ms. Pacman"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?paper orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?paper orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/iclr/0001C0USLZ20> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
What evaluation metrics are commonly used when benchmarking models on the Habitat 2020 Object Nav test-std dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Habitat 2020 Object Nav test-std"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { <https://habitat2020challenges.github.io/2020/Object_Nav/test-std> <https://dblp.org/rec/conf/robio/ChenLGWZ17> ?answer }	False
What is the top benchmark score and its metric on the BC5CDR-disease dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""BC5CDR-disease"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer_max DESC( ?metric) AS ?metric_min WHERE { ?x ?answer ?metric. ?x ?y 'BC5CDR-disease' }	False
List the metrics that are used to evaluate models on the ImageNet 64x64 benchmark dataset?	"SELECT DISTINCT ?metric ?metric_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ImageNet 64x64"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/embc/MasudaSKWIAMC12> <https://dblp.org/rdf/schema#authoredBy> ?answer }	False
List the title and ID of research papers that contain a benchmark over the DBpedia dataset?	"SELECT DISTINCT ?paper ?paper_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""DBpedia"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?paper orkgp:P31 ?cont; rdfs:label ?paper_lbl. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/ai/CalvaneseGLLR06>. ?firstanswer <https://dblp.org/rec/conf/adc/LuWYS12>. ?firstanswer <https://dblp.org/rec/conf/ismis/FerilliIF20>. ?firstanswer <https://dblp.org/rec/journals/sensors/Marin20>. ?firstanswer <https://dblp.org/rec/journals/tvt/XiaLLCG16>. ?firstanswer <https://dblp.org/rec/conf/aaai/MatsuuraH20>. ?firstanswer <https://dblp.org/rec/journals/ijon/ZhangXZ17>. ?firstanswer <https://dblp.org/rec/conf/IEEEcit/Shih04>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp.org/rec/conf/IEEEicci/ZouZZL19>. ?firstanswer <https://dblp	False
Provide a list of papers that have utilized the HRLRE model and include the links to their code?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""HRLRE"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?firstanswer ?secondanswer WHERE { ?firstanswer <https://dblp.org/rec/journals/ai/MamalakisBL20>. ?firstanswer <https://dblp.org/rec/journals/ai/Amarel85>. ?secondanswer <https://dblp.org/rec/journals/ai/Amarel85> }	False
Can you provide links to code used in papers that benchmark the T-ConvS2S model?	"SELECT DISTINCT ?code WHERE { ?model a orkgc:Model; rdfs:label ?model_lbl. FILTER (str( ?model_lbl) = ""T-ConvS2S"") ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark. ?cont orkgp:HAS_MODEL ?model; orkgp:HAS_SOURCE_CODE ?code. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/conf/naacl/RosenbergHPLCH16> ?answer }	False
Which model has achieved the highest Score score on the Atari 2600 Q*Bert benchmark dataset?	"SELECT DISTINCT ?model ?model_lbl WHERE { ?metric a orkgc:Metric; rdfs:label ?metric_lbl. FILTER (str( ?metric_lbl) = ""Score"") { SELECT ?model ?model_lbl WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Atari 2600 Q*Bert"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value; orkgp:HAS_METRIC ?metric. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } ORDER BY DESC( ?value) LIMIT 1 } }"	SELECT (GROUP_CONCAT( ?answer; separator=', ') AS ?answer) ?count WHERE { SELECT DISTINCT ?answer (COUNT( ?answer) AS ?count) WHERE { ?x score:Score ?answer. ?x dataset:Atari 2600 Q*Bert } GROUP BY ?answer } ORDER BY DESC( ?count) LIMIT 1	False
What is the top benchmark score and its metric on the Words in Context dataset?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""Words in Context"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT MAX( ?answer) AS ?answer_max MIN( ?answer) AS ?answer_min WHERE { SELECT DISTINCT ?answer ( ?answer) AS ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/KimL07> <https://dblp.org/rdf/schema#authoredBy> ?answer } UNION { ?x <https://dblp.org/rec/journals/ai/KimL07> <https://dblp.org/rdf/schema#primaryAffiliation> ?answer } }	False
List the datasets benchmarked under the Common Sense Reasoning research problem?	"SELECT DISTINCT ?dataset ?dataset_lbl WHERE { ?problem a orkgc:Problem; rdfs:label ?problem_lbl. FILTER (str( ?problem_lbl) = ""Common Sense Reasoning"") ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. ?benchmark orkgp:HAS_DATASET ?dataset. ?cont orkgp:HAS_BENCHMARK ?benchmark; orkgp:P32 ?problem. }"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ai/NieZ21> <https://dblp.org/rdf/schema#benchmarkedOn> ?answer }	False
What is the top benchmark result (metric and value) over the dataset ACE 2004?	"SELECT DISTINCT ?metric ?metric_lbl (MAX( ?value) AS ?score) WHERE { { SELECT ?metric ?metric_lbl ?value WHERE { ?dataset a orkgc:Dataset; rdfs:label ?dataset_lbl. FILTER (str( ?dataset_lbl) = ""ACE 2004"") ?benchmark orkgp:HAS_DATASET ?dataset; orkgp:HAS_EVALUATION ?eval. ?eval orkgp:HAS_VALUE ?value. OPTIONAL { ?eval orkgp:HAS_METRIC ?metric. ?metric rdfs:label ?metric_lbl. } ?cont orkgp:HAS_BENCHMARK ?benchmark. OPTIONAL { ?cont orkgp:HAS_MODEL ?model. ?model rdfs:label ?model_lbl. } } ORDER BY DESC( ?value) } } GROUP BY ?metric ?metric_lbl"	SELECT DISTINCT ?answer WHERE { ?x <https://dblp.org/rec/journals/ton/QianL16> ?answer. ?x <https://dblp.org/rdf/schema#yearOfPublication> '2016' }	False

Metrics on query only
Precision	0.1929187428804635
Recall	0.08703479766948546
F1_Score	0.10696900782361861
Blue_4	0.0005750962547804024
Bleu_Score_Cumulative	0.0012522810228235426
Meteor_Score	0.0
Rouge_1	0.2143973873381667
Rouge_2	0.043667637147831825
Rouge_L	0.2101220407297394

Metrics on all rows
Precision	0.1929187428804635
Recall	0.08703479766948546
F1_Score	0.10696900782361861
Blue_4	0.0005750962547804024
Bleu_Score_Cumulative	0.0012522810228235426
Meteor_Score	0.0
Rouge_1	0.2143973873381667
Rouge_2	0.043667637147831825
Rouge_L	0.2101220407297394

Number of sparql queries generated equal to given	0

Generated text starts with 'SELECT'	513
